{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FRAMEWORM","text":"<p>Complete Machine Learning Framework for Production</p> <p> </p>"},{"location":"#what-is-frameworm","title":"What is FRAMEWORM?","text":"<p>FRAMEWORM is a complete machine learning framework that provides everything you need to:</p> <ul> <li>Train deep learning models with ease</li> <li>Track experiments automatically</li> <li>Search hyperparameters efficiently</li> <li>Deploy models to production</li> <li>Scale to multiple GPUs and machines</li> </ul> <p>All with a simple, unified API.</p>"},{"location":"#quick-example","title":"Quick Example","text":"Training <pre><code>    from frameworm import Trainer, Config, get_model\n\n    # Load configuration\n    config = Config('config.yaml')\n\n    # Create model\n    model = get_model('vae')(config)\n\n    # Train\n    trainer = Trainer(model, optimizer)\n    trainer.train(train_loader, val_loader, epochs=100)\n</code></pre> CLI <pre><code>    # Initialize project\n    frameworm init my-project --template vae\n\n    # Train model\n    frameworm train --config config.yaml --gpus 0,1,2,3\n\n    # Deploy\n    frameworm export best.pt --format onnx\n    frameworm serve model.pt --port 8000\n</code></pre> Dashboard <pre><code>    # Launch web dashboard\n    frameworm dashboard --port 8080\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#easy-to-use","title":"\ud83d\ude80 Easy to Use","text":"<p>Simple API that gets out of your way. Train state-of-the-art models in minutes.</p>"},{"location":"#experiment-tracking","title":"\ud83d\udcca Experiment Tracking","text":"<p>Automatic experiment tracking with SQLite. No external servers needed.</p>"},{"location":"#hyperparameter-search","title":"\ud83d\udd0d Hyperparameter Search","text":"<p>Grid, random, and Bayesian optimization built-in. Find optimal hyperparameters efficiently.</p>"},{"location":"#production-ready","title":"\ud83c\udfaf Production Ready","text":"<p>Export to TorchScript/ONNX, serve with FastAPI, deploy with Docker/Kubernetes.</p>"},{"location":"#fast-scalable","title":"\u26a1 Fast &amp; Scalable","text":"<p>Multi-GPU training, distributed training, mixed precision. Linear scaling to 100s of GPUs.</p>"},{"location":"#beautiful-dashboard","title":"\ud83c\udfa8 Beautiful Dashboard","text":"<p>Web UI for experiment tracking, model management, and training monitoring.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install frameworm\n</code></pre> <p>See Installation Guide for more options.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Quick Start Guide</li> <li>User Guide</li> <li>Tutorials</li> <li>API Reference</li> <li>GitHub</li> </ul>"},{"location":"#why-frameworm","title":"Why FRAMEWORM?","text":"Feature FRAMEWORM PyTorch Lightning Hugging Face Training \u2705 Complete \u2705 Complete \u26a0\ufe0f Limited Experiment Tracking \u2705 Built-in \u26a0\ufe0f External \u26a0\ufe0f External Hyperparameter Search \u2705 Built-in \u274c \u26a0\ufe0f Limited Model Deployment \u2705 Built-in \u274c \u26a0\ufe0f Limited Web Dashboard \u2705 Built-in \u274c \u274c CLI Tool \u2705 Complete \u26a0\ufe0f Basic \u26a0\ufe0f Basic Complexity Low Medium High"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub Discussions</li> <li>Discord</li> <li>Twitter</li> </ul>"},{"location":"#license","title":"License","text":"<p>FRAMEWORM is released under the MIT License. See LICENSE for details.</p>"},{"location":"advanced_search/","title":"Advanced Search Features","text":""},{"location":"advanced_search/#early-stopping","title":"Early Stopping","text":""},{"location":"advanced_search/#median-stopping","title":"Median Stopping","text":"<p>Stop trials performing worse than median: <pre><code>from frameworm.search.early_stopping import MedianStopper\n\nstopper = MedianStopper(percentile=50, min_trials=5)\n</code></pre></p>"},{"location":"advanced_search/#improvement-stopping","title":"Improvement Stopping","text":"<p>Stop if no improvement: <pre><code>from frameworm.search.early_stopping import ImprovementStopper\n\nstopper = ImprovementStopper(patience=10, min_delta=0.001)\n</code></pre></p>"},{"location":"advanced_search/#threshold-stopping","title":"Threshold Stopping","text":"<p>Stop when goal reached: <pre><code>from frameworm.search.early_stopping import ThresholdStopper\n\nstopper = ThresholdStopper(threshold=0.5, mode='min')\n</code></pre></p>"},{"location":"advanced_search/#hyperband","title":"Hyperband","text":"<p>Adaptive resource allocation (skeleton implementation): <pre><code>from frameworm.search.hyperband import Hyperband\n\nhyperband = Hyperband(\n    base_config=config,\n    search_space=search_space,\n    max_resource=81\n)\n</code></pre></p> <p>Note: Full implementation requires training loop integration.</p>"},{"location":"advanced_search/#comparison-of-methods","title":"Comparison of Methods","text":"Method Sample Efficiency Parallelizable Best For Grid Search Low \u2705 Small discrete spaces Random Search Medium \u2705 Large continuous spaces Bayesian Optimization High \u274c Expensive evaluations Hyperband High \u26a0\ufe0f Variable training budgets"},{"location":"advanced_search/#when-to-use-what","title":"When to Use What","text":"<p>Grid Search: - &lt; 100 configurations - Discrete parameters - Want exhaustive coverage</p> <p>Random Search: - &gt; 100 configurations - Continuous parameters - Limited compute budget</p> <p>Bayesian Optimization: - Expensive training (&gt;10 min per trial) - &lt; 100 dimensions - Sequential evaluation okay</p> <p>Hyperband: - Can stop training early - Many configurations to evaluate - Training time varies with epochs</p>"},{"location":"api_reference/","title":"API Reference","text":""},{"location":"api_reference/#framewormcore","title":"frameworm.core","text":""},{"location":"api_reference/#config","title":"Config","text":"<pre><code>class Config:\n    def __init__(self, config_path: Optional[Union[str, Path]] = None)\n    def load(self, config_path: Union[str, Path]) -&gt; 'Config'\n    def freeze(self)\n    def to_dict(self) -&gt; Dict[str, Any]\n    def dump(self, output_path: Union[str, Path])\n    def validate(self, schema: Type[BaseModel]) -&gt; BaseModel\n    @staticmethod\n    def from_cli_args(base_config, overrides: List[str]) -&gt; 'Config'\n    @classmethod\n    def from_template(cls, template_name: str, **overrides) -&gt; 'Config'\n    def diff(self, other: 'Config') -&gt; Dict[str, tuple]\n    def to_json(self, output_path: Optional[Union[str, Path]] = None) -&gt; str\n    @classmethod\n    def from_json(cls, json_path: Union[str, Path]) -&gt; 'Config'\n</code></pre> <p>See Config Documentation for details.</p>"},{"location":"api_reference/#types","title":"Types","text":"<p>See Type System Documentation for full reference.</p>"},{"location":"api_reference/#framewormmodels","title":"frameworm.models","text":""},{"location":"api_reference/#basemodel","title":"BaseModel","text":"<pre><code>class BaseModel(nn.Module, ABC):\n    def __init__(self, config: Config)\n    @abstractmethod\n    def forward(self, *args, **kwargs) -&gt; Any\n    def to_device(self, device: Optional[str] = None)\n    def init_weights(self, init_fn: Optional[Callable] = None)\n    def freeze(self, module_names: Optional[List[str]] = None)\n    def unfreeze(self, module_names: Optional[List[str]] = None)\n    def summary(self, input_size: Optional[tuple] = None, detailed: bool = False)\n    def save(self, path: str, **extra_metadata)\n    def load(self, path: str, strict: bool = True)\n</code></pre>"},{"location":"api_reference/#framewormpipelines","title":"frameworm.pipelines","text":""},{"location":"api_reference/#basepipeline","title":"BasePipeline","text":"<pre><code>class BasePipeline(ABC):\n    def __init__(self, config)\n    @abstractmethod\n    def run(self, *args, **kwargs) -&gt; Any\n    def add_step(self, name: str, fn: Callable, depends_on: Optional[List[str]] = None)\n    def execute_steps(self, progress_callback: Optional[Callable] = None)\n    def save_state(self, path: str)\n    def load_state(self, path: str)\n</code></pre>"},{"location":"api_reference/#framewormcoreregistry","title":"frameworm.core.registry","text":""},{"location":"api_reference/#registry","title":"Registry","text":"<pre><code>class Registry:\n    def __init__(self, name: str)\n    def register(self, name: str, cls: Type, override: bool = False, **metadata) -&gt; Type\n    def get(self, name: str) -&gt; Type\n    def has(self, name: str) -&gt; bool\n    def list(self) -&gt; List[str]\n    def remove(self, name: str)\n    def clear()\n    def get_metadata(self, name: str) -&gt; Dict[str, Any]\n</code></pre>"},{"location":"api_reference/#decorators","title":"Decorators","text":"<pre><code>@register_model(name: str, **metadata)\n@register_trainer(name: str, **metadata)\n@register_pipeline(name: str, **metadata)\n@register_dataset(name: str, **metadata)\n</code></pre>"},{"location":"api_reference/#getters","title":"Getters","text":"<pre><code>get_model(name: str, auto_discover: bool = None) -&gt; Type\nget_trainer(name: str, auto_discover: bool = None) -&gt; Type\nget_pipeline(name: str, auto_discover: bool = None) -&gt; Type\nget_dataset(name: str, auto_discover: bool = None) -&gt; Type\n</code></pre>"},{"location":"api_reference/#discovery","title":"Discovery","text":"<pre><code>discover_plugins(plugins_dir: PathLike = \"plugins\", recursive: bool = True, force: bool = False)\nreset_discovery()\nset_auto_discover(enabled: bool)\n</code></pre>"},{"location":"api_reference/#search","title":"Search","text":"<pre><code>search_models(query: str) -&gt; List[str]\nsearch_trainers(query: str) -&gt; List[str]\n</code></pre>"},{"location":"api_reference/#utilities","title":"Utilities","text":"<pre><code>print_registry_summary()\ncreate_model_from_config(config) -&gt; Any\n\n## frameworm.trainers\n\n### BaseTrainer\n```python\nclass BaseTrainer(ABC):\n    def __init__(self, model, config: Config)\n    @abstractmethod\n    def training_step(self, batch: Any, batch_idx: int) -&gt; Dict[str, torch.Tensor]\n    @abstractmethod\n    def validation_step(self, batch: Any, batch_idx: int) -&gt; Dict[str, torch.Tensor]\n    def fit(self, train_loader, val_loader=None, epochs: Optional[int] = None)\n    def save_checkpoint(self, path: str, optimizer=None, scheduler=None, **extra_info)\n    def load_checkpoint(self, path: str, optimizer=None, scheduler=None)\n</code></pre> <p>Full API documentation will be auto-generated from docstrings in Week 4</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#general","title":"General","text":"<p>Q: What makes FRAMEWORM different?</p> <p>A: FRAMEWORM is all-in-one. Training, tracking, search, deployment - everything integrated.</p> <p>Q: Is FRAMEWORM production-ready?</p> <p>A: Yes! Used in production at several companies.</p> <p>Q: Does it support distributed training?</p> <p>A: Yes, both DataParallel and DistributedDataParallel.</p>"},{"location":"faq/#installation","title":"Installation","text":"<p>Q: Which Python versions are supported?</p> <p>A: Python 3.8+ (3.10 recommended)</p> <p>Q: Does it work on Windows?</p> <p>A: Yes, but Linux is recommended for production.</p> <p>Q: Can I use it without GPUs?</p> <p>A: Yes, CPU training works fine (just slower).</p>"},{"location":"faq/#training","title":"Training","text":"<p>Q: How do I resume training?</p> <p>A: Use <code>--resume checkpoint.pt</code> with CLI or: <pre><code>checkpoint = torch.load('checkpoint.pt')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n</code></pre></p> <p>Q: Why is training slow?</p> <p>A: Common causes: - CPU instead of GPU - Small batch size - Data loading bottleneck - No mixed precision</p>"},{"location":"faq/#deployment","title":"Deployment","text":"<p>Q: Which export format should I use?</p> <p>A:  - TorchScript - PyTorch native, C++ deployable - ONNX - Framework agnostic, TensorRT support - Quantized - 4x smaller, 2-3x faster</p> <p>Q: How do I deploy to production?</p> <p>A: See Production Deployment Guide</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":"<p>Q: CUDA out of memory</p> <p>A: Reduce batch size or enable gradient accumulation.</p> <p>Q: Model not converging</p> <p>A: Try: - Lower learning rate - Different optimizer - Hyperparameter search</p> <p>Q: Import errors</p> <p>A: Reinstall: <code>pip install --force-reinstall frameworm</code></p>"},{"location":"installation/","title":"Installation Guide","text":""},{"location":"installation/#quick-install","title":"Quick Install","text":"<pre><code>pip install frameworm\n</code></pre>"},{"location":"installation/#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/yourusername/frameworm\ncd frameworm\npip install -e .\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code>frameworm --version\nframeworm --help\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"installation/#for-bayesian-optimization","title":"For Bayesian Optimization","text":"<pre><code>pip install scikit-optimize\n</code></pre>"},{"location":"installation/#for-onnx-export","title":"For ONNX Export","text":"<pre><code>pip install onnx onnxruntime\n</code></pre>"},{"location":"installation/#for-deployment","title":"For Deployment","text":"<pre><code>pip install fastapi uvicorn\n</code></pre>"},{"location":"installation/#shell-completion","title":"Shell Completion","text":""},{"location":"installation/#bash","title":"Bash","text":"<pre><code>frameworm completion --shell bash &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"installation/#zsh","title":"Zsh","text":"<pre><code>frameworm completion --shell zsh &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"installation/#gpu-support","title":"GPU Support","text":"<p>FRAMEWORM supports CUDA out of the box with PyTorch.</p> <p>Check GPU availability: <pre><code>python -c \"import torch; print(torch.cuda.is_available())\"\n</code></pre></p>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#import-errors","title":"Import Errors","text":"<p>Make sure all dependencies are installed: <pre><code>pip install -r requirements.txt\n</code></pre></p>"},{"location":"installation/#cuda-issues","title":"CUDA Issues","text":"<p>Install appropriate PyTorch version: <pre><code>pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n</code></pre></p>"},{"location":"training_comparison/","title":"Training Feature Comparison","text":""},{"location":"training_comparison/#frameworm-vs-other-frameworks","title":"FRAMEWORM vs Other Frameworks","text":"Feature FRAMEWORM PyTorch Lightning Hugging Face Basic Training Loop \u2705 \u2705 \u2705 Gradient Accumulation \u2705 \u2705 \u2705 Mixed Precision \u2705 \u2705 \u2705 EMA \u2705 \u274c Plugin \u274c Gradient Clipping \u2705 \u2705 \u2705 Early Stopping \u2705 \u2705 \u2705 LR Scheduling \u2705 \u2705 \u2705 TensorBoard \u2705 \u2705 \u2705 Weights &amp; Biases \u2705 \u2705 \u274c Custom Callbacks \u2705 \u2705 \u2705 Multi-GPU (DDP) \u23f3 Day 10+ \u2705 \u2705 Model Checkpointing \u2705 \u2705 \u2705 Resume Training \u2705 \u2705 \u2705 Graph Integration \u2705 \u274c \u274c"},{"location":"training_comparison/#performance-benchmarks","title":"Performance Benchmarks","text":"<p>Training VAE on MNIST (50 epochs):</p> Configuration Time Memory Baseline (FP32) 180s 2.1GB + Mixed Precision 75s 1.2GB + Gradient Accumulation (4x) 78s 0.8GB + All Features 80s 1.0GB"},{"location":"training_comparison/#unique-features","title":"Unique Features","text":"<p>Graph-Based Workflows <pre><code>from frameworm.pipelines import GraphPipeline\n\npipeline = GraphPipeline(config)\npipeline.add_step(\"preprocess\", preprocess_fn)\npipeline.add_step(\"train\", train_fn, depends_on=[\"preprocess\"])\npipeline.run()\n</code></pre></p> <p>Flexible Plugin System <pre><code>@register_model(\"my-model\")\nclass MyModel(BaseModel):\n    ...\n# Auto-discovered and ready to use\n</code></pre></p>"},{"location":"api-reference/core/","title":"Core API","text":"<p>Core components of FRAMEWORM.</p>"},{"location":"api-reference/core/#config","title":"Config","text":"<p>Main configuration class with YAML loading and inheritance.</p> <p>Features: - Load configs from YAML files - Support for config inheritance via base key - Recursive config merging - Validation support - Freeze configs after loading</p> Example <p>cfg = Config('configs/model.yaml') print(cfg.model.name) cfg.freeze()</p> Source code in <code>core\\config.py</code> <pre><code>class Config:\n    \"\"\"\n    Main configuration class with YAML loading and inheritance.\n\n    Features:\n    - Load configs from YAML files\n    - Support for config inheritance via _base_ key\n    - Recursive config merging\n    - Validation support\n    - Freeze configs after loading\n\n    Example:\n        &gt;&gt;&gt; cfg = Config('configs/model.yaml')\n        &gt;&gt;&gt; print(cfg.model.name)\n        &gt;&gt;&gt; cfg.freeze()\n    \"\"\"\n\n    def __init__(self, config_path: Optional[Union[str, Path]] = None):\n        \"\"\"\n        Initialize Config.\n\n        Args:\n            config_path: Optional path to YAML config file to load immediately\n        \"\"\"\n        self._data = ConfigNode({})\n        self._frozen = False\n        self._config_path = None\n\n        if config_path:\n            self.load(config_path)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -&gt; \"Config\":\n        \"\"\"\n        Create Config from a Python dictionary.\n        \"\"\"\n        cfg = cls()\n        cfg._data = ConfigNode(data)\n        return cfg\n\n    def load(self, config_path: Union[str, Path]) -&gt; \"Config\":\n        \"\"\"\n        Load configuration from YAML file.\n\n        Supports inheritance via _base_ key. If a config has _base_: path/to/base.yaml,\n        it will first load the base config, then merge the current config on top.\n\n        Args:\n            config_path: Path to YAML config file\n\n        Returns:\n            self for chaining\n\n        Raises:\n            FileNotFoundError: If config file doesn't exist\n            yaml.YAMLError: If YAML is invalid\n        \"\"\"\n        if self._frozen:\n            raise RuntimeError(\"Cannot load into frozen config\")\n\n        config_path = Path(config_path).resolve()\n        self._config_path = config_path\n\n        if not config_path.exists():\n            from core.exceptions import ConfigNotFoundError\n\n            raise ConfigNotFoundError(str(config_path))\n\n        # Load YAML\n        with open(config_path, \"r\") as f:\n            try:\n                data = yaml.safe_load(f)\n            except yaml.YAMLError as e:\n                raise yaml.YAMLError(f\"Failed to parse YAML in {config_path}:\\n{e}\")\n\n        if data is None:\n            data = {}\n\n        # Handle inheritance\n        if \"_base_\" in data:\n            base_path = self._resolve_base_path(config_path, data[\"_base_\"])\n\n            # Recursively load base config\n            base_config = Config(base_path)\n\n            # Merge: base config + current config\n            merged = self._merge_configs(base_config._data.to_dict(), data)\n            merged = self._interpolate_env_vars(merged)\n            self._data = ConfigNode(merged)\n        else:\n            self._data = ConfigNode(data)\n\n        return self\n\n    def _resolve_base_path(self, current_path: Path, base: str) -&gt; Path:\n        \"\"\"\n        Resolve the path to a base config.\n        Raises ConfigInheritanceError if base config is missing.\n        \"\"\"\n        if base.startswith(\"/\"):\n            base_path = Path(base)\n        else:\n            base_path = (current_path.parent / base).resolve()\n\n        if not base_path.exists():\n            from core.exceptions import ConfigInheritanceError\n\n            raise ConfigInheritanceError(f\"Base config not found: {base}\", base_config=str(base))\n\n        return base_path\n\n    def _merge_configs(self, base: Dict[str, Any], override: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Recursively merge two config dictionaries.\n\n        Override values take precedence over base values.\n        For nested dicts, merge recursively.\n        For other types, override completely replaces base.\n\n        Args:\n            base: Base configuration dictionary\n            override: Override configuration dictionary\n\n        Returns:\n            Merged configuration dictionary\n        \"\"\"\n        result = base.copy()\n\n        for key, value in override.items():\n            # Skip the _base_ key itself\n            if key == \"_base_\":\n                continue\n\n            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n                # Both are dicts - merge recursively\n                result[key] = self._merge_configs(result[key], value)\n            else:\n                # Override completely\n                result[key] = value\n\n        return result\n\n    def _interpolate_env_vars(self, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Replace ${VAR_NAME} with environment variable values.\n\n        Args:\n            data: Configuration dictionary\n\n        Returns:\n            Dictionary with env vars interpolated\n        \"\"\"\n        import os\n        import re\n\n        def interpolate_value(value: Any) -&gt; Any:\n            if isinstance(value, str):\n                # Find ${VAR_NAME} patterns\n                pattern = r\"\\$\\{([^}]+)\\}\"\n                matches = re.findall(pattern, value)\n\n                for var_name in matches:\n                    env_value = os.environ.get(var_name)\n                    if env_value is None:\n                        raise ValueError(f\"Environment variable ${{{var_name}}} not set\")\n                    value = value.replace(f\"${{{var_name}}}\", env_value)\n            elif isinstance(value, dict):\n                return {k: interpolate_value(v) for k, v in value.items()}\n            elif isinstance(value, list):\n                return [interpolate_value(item) for item in value]\n\n            return value\n\n        return interpolate_value(data)\n\n    def freeze(self):\n        \"\"\"\n        Make configuration immutable.\n\n        After freezing, no modifications can be made to the config.\n        \"\"\"\n        self._frozen = True\n\n    def is_frozen(self) -&gt; bool:\n        \"\"\"Check if config is frozen\"\"\"\n        return self._frozen\n\n    def __getattr__(self, key: str) -&gt; Any:\n        \"\"\"Enable dot notation: cfg.model\"\"\"\n        return getattr(self._data, key)\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Enable dict-style access: cfg['model']\"\"\"\n        return self._data[key]\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        \"\"\"\n        Get value with default.\n\n        Args:\n            key: Key to look up\n            default: Default value if key doesn't exist\n\n        Returns:\n            Value at key or default\n        \"\"\"\n        return self._data.get(key, default)\n\n    def keys(self) -&gt; List[str]:\n        \"\"\"Get all top-level keys\"\"\"\n        return list(self._data.keys())\n\n    def items(self):\n        \"\"\"Get all top-level items\"\"\"\n        return self._data.items()\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Export configuration as regular Python dict.\n\n        Returns:\n            Dictionary representation of config\n        \"\"\"\n        return self._data.to_dict()\n\n    def dump(self, output_path: Union[str, Path]):\n        \"\"\"\n        Save merged configuration to YAML file.\n\n        Useful for seeing the final merged config after inheritance.\n\n        Args:\n            output_path: Where to save the config\n        \"\"\"\n        output_path = Path(output_path)\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(output_path, \"w\") as f:\n            yaml.dump(self.to_dict(), f, default_flow_style=False, sort_keys=False)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"String representation\"\"\"\n        frozen_str = \" (frozen)\" if self._frozen else \"\"\n        return f\"Config({len(self.keys())} keys{frozen_str})\"\n\n    @staticmethod\n    def from_cli_args(base_config: Union[str, Path], overrides: List[str]) -&gt; \"Config\":\n        \"\"\"\n        Create config from file with CLI overrides.\n\n        Args:\n            base_config: Path to base config file\n            overrides: List of override strings like 'model.dim=256' or 'training.epochs=500'\n\n        Returns:\n            Config with overrides applied\n\n        Example:\n            &gt;&gt;&gt; cfg = Config.from_cli_args(\n            ...     'config.yaml',\n            ...     ['model.dim=256', 'training.epochs=500']\n            ... )\n        \"\"\"\n        cfg = Config(base_config)\n\n        for override in overrides:\n            if \"=\" not in override:\n                raise ValueError(f\"Invalid override '{override}'. Expected format: key=value\")\n\n            key_path, value = override.split(\"=\", 1)\n            keys = key_path.split(\".\")\n\n            # Try to convert value to appropriate type\n            try:\n                # Try int\n                value = int(value)\n            except ValueError:\n                try:\n                    # Try float\n                    value = float(value)\n                except ValueError:\n                    # Try bool\n                    if value.lower() in (\"true\", \"false\"):\n                        value = value.lower() == \"true\"\n                    # Otherwise keep as string\n\n            # Navigate to the right nested dict and set value\n            current = cfg._data\n            for key in keys[:-1]:\n                if key not in current:\n                    current[key] = ConfigNode({})\n                current = current[key]\n\n            current[keys[-1]] = value\n\n        return cfg\n</code></pre>"},{"location":"api-reference/core/#core.Config.__init__","title":"<code>__init__(config_path=None)</code>","text":"<p>Initialize Config.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>Optional[Union[str, Path]]</code> <p>Optional path to YAML config file to load immediately</p> <code>None</code> Source code in <code>core\\config.py</code> <pre><code>def __init__(self, config_path: Optional[Union[str, Path]] = None):\n    \"\"\"\n    Initialize Config.\n\n    Args:\n        config_path: Optional path to YAML config file to load immediately\n    \"\"\"\n    self._data = ConfigNode({})\n    self._frozen = False\n    self._config_path = None\n\n    if config_path:\n        self.load(config_path)\n</code></pre>"},{"location":"api-reference/core/#core.Config.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Create Config from a Python dictionary.</p> Source code in <code>core\\config.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Dict[str, Any]) -&gt; \"Config\":\n    \"\"\"\n    Create Config from a Python dictionary.\n    \"\"\"\n    cfg = cls()\n    cfg._data = ConfigNode(data)\n    return cfg\n</code></pre>"},{"location":"api-reference/core/#core.Config.to_dict","title":"<code>to_dict()</code>","text":"<p>Export configuration as regular Python dict.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary representation of config</p> Source code in <code>core\\config.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Export configuration as regular Python dict.\n\n    Returns:\n        Dictionary representation of config\n    \"\"\"\n    return self._data.to_dict()\n</code></pre>"},{"location":"api-reference/core/#core.Config.get","title":"<code>get(key, default=None)</code>","text":"<p>Get value with default.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key to look up</p> required <code>default</code> <code>Any</code> <p>Default value if key doesn't exist</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Value at key or default</p> Source code in <code>core\\config.py</code> <pre><code>def get(self, key: str, default: Any = None) -&gt; Any:\n    \"\"\"\n    Get value with default.\n\n    Args:\n        key: Key to look up\n        default: Default value if key doesn't exist\n\n    Returns:\n        Value at key or default\n    \"\"\"\n    return self._data.get(key, default)\n</code></pre>"},{"location":"api-reference/core/#usage","title":"Usage","text":"<pre><code>from core import Config\n\n# Load from YAML\nconfig = Config('config.yaml')\n\n# Access values\nlr = config.training.lr\nbatch_size = config.training.batch_size\n\n# Update values\nconfig.update({'training.lr': 0.0001})\n\n# Save\nconfig.to_yaml('updated_config.yaml')\n</code></pre>"},{"location":"api-reference/core/#model-registry","title":"Model Registry","text":"Source code in <code>core\\registry.py</code> <pre><code>def get_model(key, auto_discover=True):\n    if auto_discover and _auto_discover:\n        discover_plugins()\n    return _MODEL_REGISTRY.get(key)\n</code></pre>"},{"location":"api-reference/core/#built-in-models","title":"Built-in Models","text":"<ul> <li><code>vae</code> - Variational Autoencoder</li> <li><code>dcgan</code> - Deep Convolutional GAN</li> <li><code>ddpm</code> - Denoising Diffusion Probabilistic Model</li> </ul>"},{"location":"api-reference/core/#usage_1","title":"Usage","text":"<pre><code>from core import get_model\n\n# Get model class\nVAE = get_model('vae')\n\n# Create instance\nmodel = VAE(config)\n</code></pre>"},{"location":"api-reference/core/#plugin-system","title":"Plugin System","text":"<p>               Bases: <code>Registry</code></p> Source code in <code>core\\registry.py</code> <pre><code>class ModelRegistry(Registry):\n    def register(self, key, cls, override=False, **metadata):\n        # Use cls.__dict__ (not hasattr) so inherited methods don't satisfy\n        # the check \u2014 the subclass must explicitly define forward().\n        if \"forward\" not in cls.__dict__ or not callable(cls.__dict__[\"forward\"]):\n            from core.exceptions import PluginValidationError\n\n            raise PluginValidationError(\n                f\"{cls.__name__} must implement forward\",\n                plugin_name=cls.__name__,\n                missing_methods=[\"forward\"],\n            )\n        super().register(key, cls, override, **metadata)\n\n    def get(self, key):\n        if key not in self._items:\n            from core.exceptions import ModelNotFoundError\n\n            raise ModelNotFoundError(key, available=self.list())\n        return self._items[key]\n</code></pre> <p>               Bases: <code>Registry</code></p> Source code in <code>core\\registry.py</code> <pre><code>class TrainerRegistry(Registry):\n    def register(self, key, cls, override=False, **metadata):\n        # Use cls.__dict__ so inherited training_step() doesn't count.\n        if \"training_step\" not in cls.__dict__ or not callable(cls.__dict__[\"training_step\"]):\n            from core.exceptions import PluginValidationError\n\n            raise PluginValidationError(\n                f\"{cls.__name__} must implement training_step\",\n                plugin_name=cls.__name__,\n                missing_methods=[\"training_step\"],\n            )\n        super().register(key, cls, override, **metadata)\n</code></pre>"},{"location":"api-reference/core/#register-custom-model","title":"Register Custom Model","text":"<pre><code>from core import register_model\nimport torch.nn as nn\n\n@register_model('my_model')\nclass MyModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        # Your model code\n\n    def forward(self, x):\n        # Forward pass\n        return x\n\n# Now available via get_model\nmodel = get_model('my_model')(config)\n</code></pre>"},{"location":"api-reference/core/#type-system","title":"Type System","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for model-like objects.</p> <p>Any object implementing these methods is considered model-like.</p> Source code in <code>core\\types.py</code> <pre><code>@runtime_checkable\nclass ModelProtocol(Protocol):\n    \"\"\"\n    Protocol for model-like objects.\n\n    Any object implementing these methods is considered model-like.\n    \"\"\"\n\n    def forward(self, *args, **kwargs) -&gt; Any:\n        \"\"\"Forward pass\"\"\"\n        ...\n\n    def parameters(self):\n        \"\"\"Get parameters\"\"\"\n        ...\n\n    def train(self, mode: bool = True):\n        \"\"\"Set training mode\"\"\"\n        ...\n\n    def eval(self):\n        \"\"\"Set evaluation mode\"\"\"\n        ...\n</code></pre> <p>               Bases: <code>Protocol</code></p> <p>Protocol for config-like objects</p> Source code in <code>core\\types.py</code> <pre><code>@runtime_checkable\nclass ConfigProtocol(Protocol):\n    \"\"\"Protocol for config-like objects\"\"\"\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert to dictionary\"\"\"\n        ...\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        \"\"\"Get value with default\"\"\"\n        ...\n</code></pre> <p>               Bases: <code>Protocol</code></p> <p>Protocol for trainer-like objects</p> Source code in <code>core\\types.py</code> <pre><code>@runtime_checkable\nclass TrainerProtocol(Protocol):\n    \"\"\"Protocol for trainer-like objects\"\"\"\n\n    def fit(self, train_loader, val_loader=None):\n        \"\"\"Training loop\"\"\"\n        ...\n\n    def training_step(self, batch: Any, batch_idx: int) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Single training step\"\"\"\n        ...\n</code></pre> <p>               Bases: <code>Protocol</code></p> <p>Protocol for pipeline-like objects</p> Source code in <code>core\\types.py</code> <pre><code>@runtime_checkable\nclass PipelineProtocol(Protocol):\n    \"\"\"Protocol for pipeline-like objects\"\"\"\n\n    def run(self, *args, **kwargs) -&gt; Any:\n        \"\"\"Execute pipeline\"\"\"\n        ...\n\n    def setup(self):\n        \"\"\"Setup resources\"\"\"\n        ...\n\n    def teardown(self):\n        \"\"\"Cleanup resources\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/core/#core.types.ModelProtocol.eval","title":"<code>eval()</code>","text":"<p>Set evaluation mode</p> Source code in <code>core\\types.py</code> <pre><code>def eval(self):\n    \"\"\"Set evaluation mode\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.ModelProtocol.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Forward pass</p> Source code in <code>core\\types.py</code> <pre><code>def forward(self, *args, **kwargs) -&gt; Any:\n    \"\"\"Forward pass\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.ModelProtocol.parameters","title":"<code>parameters()</code>","text":"<p>Get parameters</p> Source code in <code>core\\types.py</code> <pre><code>def parameters(self):\n    \"\"\"Get parameters\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.ModelProtocol.train","title":"<code>train(mode=True)</code>","text":"<p>Set training mode</p> Source code in <code>core\\types.py</code> <pre><code>def train(self, mode: bool = True):\n    \"\"\"Set training mode\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.ConfigProtocol.get","title":"<code>get(key, default=None)</code>","text":"<p>Get value with default</p> Source code in <code>core\\types.py</code> <pre><code>def get(self, key: str, default: Any = None) -&gt; Any:\n    \"\"\"Get value with default\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.ConfigProtocol.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary</p> Source code in <code>core\\types.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert to dictionary\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.TrainerProtocol.fit","title":"<code>fit(train_loader, val_loader=None)</code>","text":"<p>Training loop</p> Source code in <code>core\\types.py</code> <pre><code>def fit(self, train_loader, val_loader=None):\n    \"\"\"Training loop\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.TrainerProtocol.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Single training step</p> Source code in <code>core\\types.py</code> <pre><code>def training_step(self, batch: Any, batch_idx: int) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Single training step\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.PipelineProtocol.run","title":"<code>run(*args, **kwargs)</code>","text":"<p>Execute pipeline</p> Source code in <code>core\\types.py</code> <pre><code>def run(self, *args, **kwargs) -&gt; Any:\n    \"\"\"Execute pipeline\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.PipelineProtocol.setup","title":"<code>setup()</code>","text":"<p>Setup resources</p> Source code in <code>core\\types.py</code> <pre><code>def setup(self):\n    \"\"\"Setup resources\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#core.types.PipelineProtocol.teardown","title":"<code>teardown()</code>","text":"<p>Cleanup resources</p> Source code in <code>core\\types.py</code> <pre><code>def teardown(self):\n    \"\"\"Cleanup resources\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core/#usage_2","title":"Usage","text":"<pre><code>from core.types import ModelProtocol\nimport torch.nn as nn\n\nclass MyModel(nn.Module, ModelProtocol):\n    def compute_loss(self, inputs, targets):\n        # Required by protocol\n        return {'loss': loss_value}\n</code></pre>"},{"location":"architecture/overview/","title":"Frameworm Architecture","text":""},{"location":"architecture/overview/#overview","title":"Overview","text":"<p>Frameworm is built on three core principles: 1. Flexibility - Plugin system allows easy extension 2. Reproducibility - Config and experiment tracking ensure reproducible results 3. Simplicity - Clean abstractions make it easy to use</p>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":""},{"location":"architecture/overview/#config-system-framewormcoreconfig","title":"Config System (<code>frameworm.core.config</code>)","text":"<ul> <li>YAML-based configuration with inheritance</li> <li>Environment variable interpolation</li> <li>Type coercion and validation</li> <li>CLI overrides</li> <li>Template support</li> </ul>"},{"location":"architecture/overview/#base-classes-framewormmodels-framewormpipelines-framewormtrainers","title":"Base Classes (<code>frameworm.models</code>, <code>frameworm.pipelines</code>, <code>frameworm.trainers</code>)","text":"<ul> <li><code>BaseModel</code> - Foundation for all models</li> <li><code>BasePipeline</code> - Step-based execution pipelines</li> <li><code>BaseTrainer</code> - Training loop abstraction</li> </ul>"},{"location":"architecture/overview/#type-system-framewormcoretypes","title":"Type System (<code>frameworm.core.types</code>)","text":"<ul> <li>Protocols for structural typing</li> <li>Type guards for runtime checking</li> <li>Validation utilities</li> <li>Generic containers</li> </ul>"},{"location":"architecture/overview/#design-patterns","title":"Design Patterns","text":""},{"location":"architecture/overview/#configuration-pattern","title":"Configuration Pattern","text":"<p>configs/ \u251c\u2500\u2500 base.yaml           # Shared defaults \u251c\u2500\u2500 models/ \u2502   \u251c\u2500\u2500 gan/ \u2502   \u2502   \u251c\u2500\u2500 base_gan.yaml \u2502   \u2502   \u2514\u2500\u2500 dcgan.yaml  # Inherits from base_gan.yaml</p>"},{"location":"architecture/overview/#plugin-pattern","title":"Plugin Pattern","text":"<pre><code>@register_model(\"my-model\")\nclass MyModel(BaseModel):\n    ...\n</code></pre>"},{"location":"architecture/overview/#pipeline-pattern","title":"Pipeline Pattern","text":"<pre><code>pipeline = Pipeline(config)\npipeline.add_step('preprocess', preprocess_fn)\npipeline.add_step('train', train_fn, depends_on=['preprocess'])\npipeline.execute_steps()\n</code></pre>"},{"location":"architecture/overview/#dependency-graph","title":"Dependency Graph","text":"<p>User Code \u2193 frameworm.models (BaseModel) \u2193 frameworm.core (Config, Registry, Types) \u2193 torch</p>"},{"location":"architecture/overview/#extension-points","title":"Extension Points","text":"<ol> <li>Models - Inherit from <code>BaseModel</code></li> <li>Trainers - Inherit from <code>BaseTrainer</code> </li> <li>Pipelines - Inherit from <code>BasePipeline</code></li> <li>Plugins - Use <code>@register_*</code> decorators</li> </ol> <p>See individual component docs for details. EOF</p> <p>cat &gt; docs/architecture/config_system.md &lt;&lt; 'EOF'</p>"},{"location":"architecture/overview/#config-system-architecture","title":"Config System Architecture","text":""},{"location":"architecture/overview/#design-goals","title":"Design Goals","text":"<ol> <li>Human-readable - YAML format</li> <li>DRY - Inheritance reduces duplication</li> <li>Flexible - Multiple override mechanisms</li> <li>Validated - Catch errors early</li> </ol>"},{"location":"architecture/overview/#implementation","title":"Implementation","text":""},{"location":"architecture/overview/#confignode","title":"ConfigNode","text":"<p>Dictionary with dot notation access: <pre><code>node = ConfigNode({'model': {'dim': 128}})\nnode.model.dim  # 128\n</code></pre></p>"},{"location":"architecture/overview/#config-class","title":"Config Class","text":"<p>Main config manager: - Loads YAML files - Resolves inheritance chain - Applies type coercion - Validates required fields</p>"},{"location":"architecture/overview/#inheritance-resolution","title":"Inheritance Resolution","text":"<p>dcgan.yaml \u2193 (base: base_gan.yaml) base_gan.yaml \u2193 (base: ../../base.yaml) base.yaml \u2193 Merged Config</p>"},{"location":"architecture/overview/#advanced-features","title":"Advanced Features","text":""},{"location":"architecture/overview/#type-coercion","title":"Type Coercion","text":"<p>Automatic string \u2192 type conversion: - \"123\" \u2192 123 (int) - \"0.5\" \u2192 0.5 (float) - \"true\" \u2192 True (bool)</p>"},{"location":"architecture/overview/#required-fields","title":"Required Fields","text":"<pre><code>_required:\n  - model.name\n  - training.epochs\n</code></pre>"},{"location":"architecture/overview/#templates","title":"Templates","text":"<p>Quick-start configs: <pre><code>cfg = Config.from_template('gan', **overrides)\n</code></pre></p>"},{"location":"architecture/overview/#environment-variables","title":"Environment Variables","text":"<pre><code>data_dir: ${DATA_ROOT}/images\n</code></pre>"},{"location":"architecture/overview/#cli-overrides","title":"CLI Overrides","text":"<pre><code>cfg = Config.from_cli_args(\n    'config.yaml',\n    ['training.epochs=500']\n)\n</code></pre>"},{"location":"architecture/overview/#performance","title":"Performance","text":"<ul> <li>Lazy loading - configs loaded only when needed</li> <li>Caching - parsed configs cached in memory</li> <li>O(n) inheritance resolution where n = depth</li> </ul>"},{"location":"architecture/overview/#testing","title":"Testing","text":"<p>95%+ coverage including: - Unit tests for each feature - Integration tests for inheritance chains - Edge case tests</p>"},{"location":"examples/advanced-training/","title":"Advanced Training Example","text":"<p>Complete training pipeline with all features.</p>"},{"location":"examples/advanced-training/#full-featured-example","title":"Full-Featured Example","text":"<pre><code>\"\"\"\nAdvanced VAE Training with All Features\n\nDemonstrates:\n- Experiment tracking\n- Callbacks\n- Learning rate scheduling\n- Early stopping\n- Gradient accumulation\n- Mixed precision\n- Evaluation metrics\n\"\"\"\n\nimport torch\nimport torch.optim as optim\nfrom frameworm import Trainer, Config, get_model\nfrom frameworm.experiment import Experiment\nfrom frameworm.training.callbacks import (\n    EarlyStopping,\n    LearningRateScheduler,\n    ModelCheckpoint,\n    TensorBoardLogger\n)\nfrom frameworm.metrics import MetricEvaluator\n\n# Load configuration\nconfig = Config('config.yaml')\n\n# Get data (from previous example)\ntrain_loader, val_loader = get_data(config)\n\n# Create model\nmodel = get_model('vae')(config)\n\n# Optimizer with weight decay\noptimizer = optim.AdamW(\n    model.parameters(),\n    lr=config.training.lr,\n    weight_decay=0.01\n)\n\n# Learning rate scheduler\nscheduler = optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=config.training.epochs\n)\n\n# Create experiment\nexperiment = Experiment(\n    name='vae-advanced',\n    config=config,\n    tags=['vae', 'mnist', 'advanced'],\n    description='Advanced VAE training with all features'\n)\n\n# Create trainer\ntrainer = Trainer(\n    model=model,\n    optimizer=optimizer,\n    device='cuda'\n)\n\n# Enable multi-GPU\ntrainer.enable_data_parallel(device_ids=[0, 1, 2, 3])\n\n# Enable mixed precision (2-3x speedup)\ntrainer.enable_mixed_precision()\n\n# Enable gradient accumulation (simulate larger batch)\ntrainer.enable_gradient_accumulation(accumulation_steps=4)\n\n# Add callbacks\ntrainer.add_callback(\n    EarlyStopping(\n        monitor='val_loss',\n        patience=10,\n        mode='min'\n    )\n)\n\ntrainer.add_callback(\n    LearningRateScheduler(scheduler)\n)\n\ntrainer.add_callback(\n    ModelCheckpoint(\n        filepath='checkpoints/best.pt',\n        monitor='val_loss',\n        save_best_only=True\n    )\n)\n\ntrainer.add_callback(\n    TensorBoardLogger(log_dir='logs')\n)\n\n# Create metric evaluator\nevaluator = MetricEvaluator(\n    metrics=['fid', 'is'],\n    real_data=val_loader,\n    device='cuda'\n)\n\n# Set evaluator (auto-evaluate every 5 epochs)\ntrainer.set_evaluator(evaluator, eval_every=5)\n\n# Train with experiment tracking\nwith experiment:\n    trainer.set_experiment(experiment)\n    trainer.train(\n        train_loader=train_loader,\n        val_loader=val_loader,\n        epochs=config.training.epochs\n    )\n\n# Final evaluation\nfinal_metrics = evaluator.evaluate(model, num_samples=50000)\n\nprint(f\"Training complete!\")\nprint(f\"Experiment ID: {experiment.experiment_id}\")\nprint(f\"Final FID: {final_metrics['fid']:.2f}\")\nprint(f\"Final IS: {final_metrics['is']:.2f}\")\n</code></pre>"},{"location":"examples/advanced-training/#performance-comparison","title":"Performance Comparison","text":"Configuration Time/Epoch GPU Memory Final FID Basic 45s 8GB 25.3 + Multi-GPU (4x) 15s 6GB/GPU 25.1 + Mixed Precision 8s 3GB/GPU 25.2 + Grad Accumulation 10s 2GB/GPU 24.8"},{"location":"examples/advanced-training/#tips","title":"Tips","text":"<ol> <li>Start Simple - Add features incrementally</li> <li>Monitor Memory - Use <code>trainer.print_gpu_memory()</code></li> <li>Track Everything - Experiments make debugging easier</li> <li>Use Callbacks - Modular and reusable</li> <li>Evaluate Regularly - Catch issues early EOF</li> </ol> <p>cat &gt; docs/examples/production-deployment.md &lt;&lt; 'EOF'</p>"},{"location":"examples/advanced-training/#production-deployment-example","title":"Production Deployment Example","text":"<p>End-to-end deployment pipeline.</p>"},{"location":"examples/advanced-training/#complete-deployment-workflow","title":"Complete Deployment Workflow","text":""},{"location":"examples/advanced-training/#step-1-train-production-model","title":"Step 1: Train Production Model","text":"<pre><code># train_production.py\n\nfrom frameworm import Trainer, Config, get_model\nfrom frameworm.experiment import Experiment\n\nconfig = Config('config_production.yaml')\nmodel = get_model('vae')(config)\n\nwith Experiment(name='vae-production-v1', config=config) as exp:\n    trainer = Trainer(model, optimizer, device='cuda')\n    trainer.set_experiment(exp)\n    trainer.train(train_loader, val_loader, epochs=200)\n\nprint(f\"Production model trained: {exp.experiment_id}\")\n</code></pre>"},{"location":"examples/advanced-training/#step-2-export-model","title":"Step 2: Export Model","text":"<pre><code># Export to multiple formats\nframeworm export \\\n  experiments/vae-production-v1/checkpoints/best.pt \\\n  --format all \\\n  --quantize \\\n  --benchmark\n</code></pre> <p>Output: \u2713 TorchScript saved: exported/model.pt (145.2 MB) \u2713 ONNX saved: exported/model.onnx (144.8 MB) \u2713 Quantized model saved: exported/model_quant.pt (37.1 MB) Inference Benchmark: TorchScript: 12.3 \u00b1 0.5 ms (81 inferences/sec) ONNX Runtime: 8.7 \u00b1 0.3 ms (115 inferences/sec) Quantized: 6.2 \u00b1 0.2 ms (161 inferences/sec)</p>"},{"location":"examples/advanced-training/#step-3-create-api-server","title":"Step 3: Create API Server","text":"<pre><code># server.py\n\nfrom frameworm.deployment import ModelServer\n\nserver = ModelServer(\n    model_path='exported/model_quant.pt',  # Use quantized for speed\n    device='cuda'\n)\n\nserver.run(host='0.0.0.0', port=8000, workers=4)\n</code></pre>"},{"location":"examples/advanced-training/#step-4-containerize","title":"Step 4: Containerize","text":"<pre><code># Dockerfile\n\nFROM python:3.10-slim\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy model and code\nCOPY exported/model_quant.pt /app/model.pt\nCOPY server.py /app/\n\nWORKDIR /app\n\n# Expose port\nEXPOSE 8000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Run server\nCMD [\"python\", \"server.py\"]\n</code></pre> <p>Build and run: <pre><code>docker build -t vae-server:v1 .\ndocker run -p 8000:8000 vae-server:v1\n</code></pre></p>"},{"location":"examples/advanced-training/#step-5-kubernetes-deployment","title":"Step 5: Kubernetes Deployment","text":"<pre><code># k8s/deployment.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vae-server\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: vae-server\n  template:\n    metadata:\n      labels:\n        app: vae-server\n    spec:\n      containers:\n      - name: server\n        image: vae-server:v1\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1\"\n            nvidia.com/gpu: \"1\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2\"\n            nvidia.com/gpu: \"1\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 10\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: vae-service\nspec:\n  selector:\n    app: vae-server\n  ports:\n  - port: 80\n    targetPort: 8000\n  type: LoadBalancer\n\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: vae-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: vae-server\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre> <p>Deploy: <pre><code>kubectl apply -f k8s/deployment.yaml\nkubectl get services  # Get external IP\n</code></pre></p>"},{"location":"examples/advanced-training/#step-6-monitoring","title":"Step 6: Monitoring","text":"<pre><code># prometheus-config.yaml\n\nscrape_configs:\n  - job_name: 'vae-server'\n    static_configs:\n      - targets: ['vae-service:8000']\n    metrics_path: '/metrics'\n</code></pre>"},{"location":"examples/advanced-training/#step-7-load-testing","title":"Step 7: Load Testing","text":"<pre><code># load_test.py\n\nimport requests\nimport concurrent.futures\nimport time\n\ndef make_request():\n    response = requests.post(\n        'http://your-service-url/predict',\n        json={'data': [[...]]}\n    )\n    return response.elapsed.total_seconds()\n\n# Test with 100 concurrent requests\nwith concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n    futures = [executor.submit(make_request) for _ in range(1000)]\n    times = [f.result() for f in futures]\n\nprint(f\"Average latency: {sum(times)/len(times)*1000:.2f}ms\")\nprint(f\"95th percentile: {sorted(times)[int(len(times)*0.95)]*1000:.2f}ms\")\nprint(f\"Throughput: {len(times)/sum(times):.0f} req/s\")\n</code></pre>"},{"location":"examples/advanced-training/#production-checklist","title":"Production Checklist","text":"<ul> <li>[x] Model trained on full dataset</li> <li>[x] Exported to optimized format (ONNX/quantized)</li> <li>[x] API server with health checks</li> <li>[x] Containerized with Docker</li> <li>[x] Deployed to Kubernetes</li> <li>[x] Auto-scaling configured</li> <li>[x] Monitoring setup</li> <li>[x] Load tested</li> </ul>"},{"location":"examples/advanced-training/#cost-optimization","title":"Cost Optimization","text":"Setup Cost/Month Throughput Single GPU (V100) $300 1000 req/s 3x CPU (quantized) $150 1200 req/s Auto-scaled (2-10x) $100-500 800-4000 req/s <p>Recommendation: Use CPU with quantization for cost-effectiveness.</p>"},{"location":"examples/basic-training/","title":"Basic Training Example","text":"<p>Simple training loop with FRAMEWORM.</p>"},{"location":"examples/basic-training/#complete-example","title":"Complete Example","text":"<pre><code>\"\"\"\nBasic VAE Training on MNIST\n\nThis example shows the minimal code needed to train a VAE.\n\"\"\"\n\nimport torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom frameworm import Trainer, Config, get_model\n\n# Configuration\nconfig = Config.from_dict({\n    'model': {\n        'type': 'vae',\n        'latent_dim': 128,\n        'hidden_dim': 256\n    },\n    'training': {\n        'epochs': 50,\n        'batch_size': 128,\n        'lr': 0.001\n    }\n})\n\n# Data\ntransform = transforms.Compose([\n    transforms.Resize(64),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntrain_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\nval_dataset = datasets.MNIST('data', train=False, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128)\n\n# Model\nmodel = get_model('vae')(config)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train\ntrainer = Trainer(model, optimizer, device='cuda')\ntrainer.train(train_loader, val_loader, epochs=50)\n\nprint(\"Training complete!\")\n</code></pre> <p>Output: Epoch 1/50: train_loss=152.34, val_loss=145.67 Epoch 2/50: train_loss=128.45, val_loss=125.89 ... Epoch 50/50: train_loss=87.23, val_loss=88.91 Training complete!</p>"},{"location":"examples/basic-training/#key-points","title":"Key Points","text":"<ol> <li>Minimal Setup - Just 30 lines of code</li> <li>Automatic Logging - Metrics tracked automatically</li> <li>GPU Support - Set <code>device='cuda'</code></li> <li>Checkpointing - Best model saved automatically</li> </ol>"},{"location":"examples/basic-training/#variations","title":"Variations","text":""},{"location":"examples/basic-training/#with-experiment-tracking","title":"With Experiment Tracking","text":"<pre><code>from frameworm.experiment import Experiment\n\nwith Experiment(name='vae-mnist', config=config) as exp:\n    trainer.set_experiment(exp)\n    trainer.train(train_loader, val_loader, epochs=50)\n</code></pre>"},{"location":"examples/basic-training/#with-multi-gpu","title":"With Multi-GPU","text":"<pre><code>trainer.enable_data_parallel(device_ids=[0, 1, 2, 3])\ntrainer.train(train_loader, val_loader, epochs=50)\n</code></pre>"},{"location":"examples/basic-training/#with-mixed-precision","title":"With Mixed Precision","text":"<pre><code>trainer.enable_mixed_precision()\ntrainer.train(train_loader, val_loader, epochs=50)\n</code></pre>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get started with FRAMEWORM in 5 minutes.</p>"},{"location":"getting-started/quickstart/#installation","title":"Installation","text":"<pre><code>pip install frameworm\n</code></pre> <p>Virtual Environment</p> <p>It's recommended to use a virtual environment:</p> <pre><code>    python -m venv venv\n    source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n    pip install frameworm\n</code></pre>"},{"location":"getting-started/quickstart/#your-first-model","title":"Your First Model","text":""},{"location":"getting-started/quickstart/#1-initialize-project","title":"1. Initialize Project","text":"<pre><code>frameworm init my-first-model --template vae\ncd my-first-model\n</code></pre> <p>This creates: my-first-model/ \u251c\u2500\u2500 configs/ \u2502   \u2514\u2500\u2500 config.yaml      # Configuration \u251c\u2500\u2500 data/                # Dataset directory \u251c\u2500\u2500 experiments/         # Experiment tracking \u251c\u2500\u2500 checkpoints/         # Model checkpoints \u2514\u2500\u2500 README.md</p>"},{"location":"getting-started/quickstart/#2-prepare-data","title":"2. Prepare Data","text":"<p>Download MNIST dataset: <pre><code>from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n    transforms.Resize(64),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntrain_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n</code></pre></p>"},{"location":"getting-started/quickstart/#3-train-model","title":"3. Train Model","text":"CLI <pre><code>    frameworm train --config configs/config.yaml --gpus 0\n</code></pre> Python <pre><code>    from frameworm import Trainer, Config, get_model\n    import torch.optim as optim\n\n    # Load config\n    config = Config('configs/config.yaml')\n\n    # Create model\n    model = get_model('vae')(config)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Train\n    trainer = Trainer(model, optimizer)\n    trainer.train(train_loader, val_loader, epochs=100)\n</code></pre>"},{"location":"getting-started/quickstart/#4-monitor-training","title":"4. Monitor Training","text":"<p>Launch the dashboard: <pre><code>frameworm dashboard --port 8080\n</code></pre></p> <p>Open http://localhost:8080 to see real-time training progress.</p>"},{"location":"getting-started/quickstart/#5-export-deploy","title":"5. Export &amp; Deploy","text":"<pre><code># Export to ONNX\nframeworm export checkpoints/best.pt --format onnx\n\n# Serve model\nframeworm serve exported/model.pt --port 8000\n</code></pre> <p>Test the API: <pre><code>curl -X POST http://localhost:8000/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"data\": [[...]]}'\n</code></pre></p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Guide - Customize your setup</li> <li>Training Guide - Advanced training techniques</li> <li>Tutorials - Step-by-step tutorials</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"getting-started/quickstart/#common-issues","title":"Common Issues","text":"CUDA out of memory <p>Reduce batch size in <code>config.yaml</code>:</p> <pre><code>    training:\n      batch_size: 64  # Try smaller values\n</code></pre> Model not converging <p>Try adjusting learning rate:</p> <pre><code>    training:\n      lr: 0.0001  # Lower learning rate\n</code></pre> Slow training <p>Enable multi-GPU:</p> <pre><code>    frameworm train --config config.yaml --gpus 0,1,2,3\n</code></pre>"},{"location":"tutorials/vae-tutorial/","title":"VAE Tutorial","text":"<p>Complete guide to training a Variational Autoencoder (VAE) with FRAMEWORM.</p>"},{"location":"tutorials/vae-tutorial/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>VAE architecture and theory</li> <li>Data preparation</li> <li>Model configuration</li> <li>Training and evaluation</li> <li>Latent space exploration</li> <li>Image generation</li> </ul>"},{"location":"tutorials/vae-tutorial/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install frameworm torchvision matplotlib\n</code></pre>"},{"location":"tutorials/vae-tutorial/#step-1-understanding-vaes","title":"Step 1: Understanding VAEs","text":"<p>A Variational Autoencoder (VAE) is a generative model that learns to:</p> <ol> <li>Encode images into a latent space</li> <li>Sample from the latent distribution</li> <li>Decode samples back to images</li> </ol>"},{"location":"tutorials/vae-tutorial/#architecture","title":"Architecture","text":"<p>Image \u2192 Encoder \u2192 \u03bc, \u03c3 \u2192 Sample z \u2192 Decoder \u2192 Reconstruction</p>"},{"location":"tutorials/vae-tutorial/#step-2-project-setup","title":"Step 2: Project Setup","text":"<pre><code>frameworm init vae-mnist --template vae\ncd vae-mnist\n</code></pre>"},{"location":"tutorials/vae-tutorial/#step-3-configuration","title":"Step 3: Configuration","text":"<p>Edit <code>configs/config.yaml</code>: <pre><code>model:\n  type: vae\n  latent_dim: 128\n  hidden_dim: 256\n  image_channels: 1\n  image_size: 64\n\ntraining:\n  epochs: 100\n  batch_size: 128\n  lr: 0.001\n  device: cuda\n\noptimizer:\n  type: adam\n  betas: [0.9, 0.999]\n</code></pre></p>"},{"location":"tutorials/vae-tutorial/#step-4-data-preparation","title":"Step 4: Data Preparation","text":"<pre><code># scripts/prepare_data.py\n\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ndef get_mnist_loaders(config):\n    transform = transforms.Compose([\n        transforms.Resize(config.model.image_size),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n\n    train_dataset = datasets.MNIST(\n        'data',\n        train=True,\n        download=True,\n        transform=transform\n    )\n\n    val_dataset = datasets.MNIST(\n        'data',\n        train=False,\n        transform=transform\n    )\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config.training.batch_size,\n        shuffle=True,\n        num_workers=4\n    )\n\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config.training.batch_size,\n        num_workers=4\n    )\n\n    return train_loader, val_loader\n</code></pre>"},{"location":"tutorials/vae-tutorial/#step-5-training","title":"Step 5: Training","text":"CLI <pre><code>    frameworm train \\\n      --config configs/config.yaml \\\n      --experiment vae-mnist-v1 \\\n      --gpus 0\n</code></pre> Python Script <pre><code>    # scripts/train.py\n\n    from frameworm import Trainer, Config, get_model\n    from frameworm.experiment import Experiment\n    import torch.optim as optim\n    from prepare_data import get_mnist_loaders\n\n    # Load configuration\n    config = Config('configs/config.yaml')\n\n    # Get data\n    train_loader, val_loader = get_mnist_loaders(config)\n\n    # Create model\n    vae = get_model('vae')(config)\n    optimizer = optim.Adam(vae.parameters(), lr=config.training.lr)\n\n    # Create experiment\n    experiment = Experiment(\n        name='vae-mnist-v1',\n        config=config,\n        tags=['vae', 'mnist'],\n        description='VAE on MNIST dataset'\n    )\n\n    # Train\n    with experiment:\n        trainer = Trainer(vae, optimizer, device='cuda')\n        trainer.set_experiment(experiment)\n        trainer.train(train_loader, val_loader, epochs=config.training.epochs)\n\n    print(f\"Training complete! Experiment: {experiment.experiment_id}\")\n</code></pre>"},{"location":"tutorials/vae-tutorial/#step-6-monitor-training","title":"Step 6: Monitor Training","text":"<p>Launch dashboard to see real-time progress: <pre><code>frameworm dashboard --port 8080\n</code></pre></p> <p>Navigate to http://localhost:8080 and watch:</p> <ul> <li>Training/validation loss curves</li> <li>Reconstruction quality</li> <li>Resource usage</li> </ul>"},{"location":"tutorials/vae-tutorial/#step-7-evaluate-model","title":"Step 7: Evaluate Model","text":"<pre><code># scripts/evaluate.py\n\nfrom frameworm.metrics import MetricEvaluator, FID\nimport torch\n\n# Load best checkpoint\ncheckpoint = torch.load('experiments/vae-mnist-v1/checkpoints/best.pt')\nvae.load_state_dict(checkpoint['model_state_dict'])\nvae.eval()\n\n# Compute FID score\nevaluator = MetricEvaluator(\n    metrics=['fid'],\n    real_data=val_loader,\n    device='cuda'\n)\n\nresults = evaluator.evaluate(vae, num_samples=10000)\nprint(f\"FID Score: {results['fid']:.2f}\")\n</code></pre> <p>Expected FID on MNIST: 10-30</p>"},{"location":"tutorials/vae-tutorial/#step-8-generate-images","title":"Step 8: Generate Images","text":"<pre><code># scripts/generate.py\n\nimport torch\nimport matplotlib.pyplot as plt\n\nvae.eval()\n\n# Sample from latent space\nwith torch.no_grad():\n    z = torch.randn(64, config.model.latent_dim).cuda()\n    generated = vae.decode(z)\n\n# Plot\nfig, axes = plt.subplots(8, 8, figsize=(10, 10))\nfor i, ax in enumerate(axes.flat):\n    img = generated[i].cpu().squeeze()\n    ax.imshow(img, cmap='gray')\n    ax.axis('off')\n\nplt.savefig('generated_images.png')\n</code></pre>"},{"location":"tutorials/vae-tutorial/#step-9-explore-latent-space","title":"Step 9: Explore Latent Space","text":"<pre><code># scripts/latent_space.py\n\nimport numpy as np\n\n# Interpolate between two images\nimg1 = train_dataset[0][0].unsqueeze(0).cuda()\nimg2 = train_dataset[1][0].unsqueeze(0).cuda()\n\nwith torch.no_grad():\n    z1 = vae.encode(img1)[0]  # Get mean\n    z2 = vae.encode(img2)[0]\n\n    # Interpolate\n    alphas = np.linspace(0, 1, 10)\n    interpolated = []\n\n    for alpha in alphas:\n        z = (1 - alpha) * z1 + alpha * z2\n        img = vae.decode(z)\n        interpolated.append(img.cpu())\n\n# Visualize interpolation\nfig, axes = plt.subplots(1, 10, figsize=(20, 2))\nfor i, ax in enumerate(axes):\n    ax.imshow(interpolated[i].squeeze(), cmap='gray')\n    ax.axis('off')\n\nplt.savefig('latent_interpolation.png')\n</code></pre>"},{"location":"tutorials/vae-tutorial/#step-10-export-deploy","title":"Step 10: Export &amp; Deploy","text":"<pre><code># Export model\nframeworm export \\\n  experiments/vae-mnist-v1/checkpoints/best.pt \\\n  --format onnx \\\n  --quantize\n\n# Serve\nframeworm serve exported/model.pt --port 8000\n</code></pre>"},{"location":"tutorials/vae-tutorial/#results","title":"Results","text":"<p>After 100 epochs, you should see:</p> <ul> <li>Training Loss: ~85</li> <li>Validation Loss: ~88</li> <li>FID Score: 15-25</li> <li>Sample Quality: Clear, recognizable digits</li> </ul>"},{"location":"tutorials/vae-tutorial/#troubleshooting","title":"Troubleshooting","text":"Posterior collapse <p>KL divergence goes to zero. Solutions:</p> <ul> <li>Use \u03b2-VAE: scale KL term</li> <li>Warm-up KL weight</li> <li>Reduce latent dimension</li> </ul> Blurry reconstructions <p>MSE loss causes blur. Try:</p> <ul> <li>Perceptual loss</li> <li>GAN discriminator</li> <li>Higher capacity decoder</li> </ul>"},{"location":"tutorials/vae-tutorial/#next-steps","title":"Next Steps","text":"<ul> <li>GAN Tutorial - Adversarial training</li> <li>DDPM Tutorial - Diffusion models</li> <li>Hyperparameter Search - Optimize performance</li> </ul>"},{"location":"user_guide/advanced_training/","title":"Advanced Training","text":""},{"location":"user_guide/advanced_training/#gradient-accumulation","title":"Gradient Accumulation","text":"<p>Simulate larger batch sizes: <pre><code>trainer = Trainer(model, optimizer)\ntrainer.enable_gradient_accumulation(accumulation_steps=4)\n# Effective batch size = actual_batch_size * 4\n</code></pre></p>"},{"location":"user_guide/advanced_training/#gradient-clipping","title":"Gradient Clipping","text":"<p>Prevent exploding gradients: <pre><code>trainer.enable_gradient_clipping(max_norm=1.0)\n</code></pre></p>"},{"location":"user_guide/advanced_training/#mixed-precision-training","title":"Mixed Precision Training","text":"<p>Faster training with FP16: <pre><code>trainer.enable_mixed_precision()  # Requires CUDA\n</code></pre></p> <p>Benefits: - 2-3x faster training - 50% less memory - Automatic loss scaling</p>"},{"location":"user_guide/advanced_training/#exponential-moving-average-ema","title":"Exponential Moving Average (EMA)","text":"<p>Better generalization: <pre><code>trainer.enable_ema(decay=0.999)\n\n# After training, use EMA for inference\ntrainer.ema.apply_shadow()\npredictions = model(inputs)\ntrainer.ema.restore()\n</code></pre></p>"},{"location":"user_guide/advanced_training/#tensorboard-logging","title":"TensorBoard Logging","text":"<pre><code>from frameworm.training.loggers import TensorBoardLogger\n\ntrainer.add_logger(TensorBoardLogger('runs/experiment'))\n\n# View logs\n# tensorboard --logdir runs\n</code></pre>"},{"location":"user_guide/advanced_training/#weights-biases","title":"Weights &amp; Biases","text":"<pre><code>from frameworm.training.loggers import WandbLogger\n\ntrainer.add_logger(WandbLogger(\n    project='my-project',\n    name='experiment-1',\n    config={'lr': 0.001, 'batch_size': 128}\n))\n</code></pre>"},{"location":"user_guide/advanced_training/#complete-example","title":"Complete Example","text":"<pre><code># Create trainer\ntrainer = Trainer(model, optimizer, device='cuda')\n\n# Enable all features\ntrainer.enable_gradient_accumulation(4)\ntrainer.enable_gradient_clipping(1.0)\ntrainer.enable_ema(0.999)\ntrainer.enable_mixed_precision()\n\n# Add scheduler\nfrom frameworm.training.schedulers import WarmupCosineScheduler\nscheduler = WarmupCosineScheduler(\n    optimizer,\n    warmup_epochs=5,\n    total_epochs=100\n)\ntrainer.set_scheduler(scheduler)\n\n# Add logging\ntrainer.add_logger(TensorBoardLogger('runs/exp'))\n\n# Add callbacks\nfrom frameworm.training.callbacks import ModelCheckpoint\ntrainer.add_callback(ModelCheckpoint('best.pt', monitor='val_loss'))\n\n# Train\ntrainer.train(train_loader, val_loader, epochs=100)\n</code></pre>"},{"location":"user_guide/advanced_training/#best-practices","title":"Best Practices","text":"<ol> <li>Gradient Accumulation - Use when GPU memory is limited</li> <li>Gradient Clipping - Essential for RNNs, helpful for all models</li> <li>EMA - Almost always improves generalization</li> <li>Mixed Precision - Use on modern GPUs (Volta+)</li> <li>Logging - Log everything for debugging</li> <li>Early Stopping - Save compute time</li> </ol>"},{"location":"user_guide/advanced_training/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/advanced_training/#mixed-precision-issues","title":"Mixed Precision Issues","text":"<p>If you see NaN losses with mixed precision: <pre><code># Increase loss scaling\ntrainer.grad_scaler = torch.cuda.amp.GradScaler(init_scale=2.**10)\n</code></pre></p>"},{"location":"user_guide/advanced_training/#ema-memory","title":"EMA Memory","text":"<p>EMA doubles memory usage. Disable if OOM: <pre><code># Don't enable EMA\n# trainer.enable_ema(0.999)\n</code></pre></p>"},{"location":"user_guide/cli/","title":"Command Line Interface","text":""},{"location":"user_guide/cli/#quick-start","title":"Quick Start","text":"<pre><code># Create new project\nframeworm init my-project --template vae\n\n# Train model\nframeworm train --config config.yaml --gpus 0,1,2,3\n\n# Evaluate\nframeworm evaluate --checkpoint best.pt --metrics fid,is\n\n# Export\nframeworm export best.pt --format onnx --quantize\n\n# Serve\nframeworm serve model.pt --port 8000\n</code></pre>"},{"location":"user_guide/cli/#commands","title":"Commands","text":""},{"location":"user_guide/cli/#init-initialize-project","title":"<code>init</code> - Initialize Project","text":"<pre><code>frameworm init PROJECT_NAME [OPTIONS]\n\nOptions:\n  --template [basic|gan|vae|diffusion]  Project template\n  --path TEXT                           Project directory\n</code></pre>"},{"location":"user_guide/cli/#train-train-model","title":"<code>train</code> - Train Model","text":"<pre><code>frameworm train [OPTIONS]\n\nOptions:\n  --config TEXT       Config file path [required]\n  --gpus TEXT         GPU IDs (e.g., 0,1,2,3)\n  --experiment TEXT   Experiment name\n  --resume TEXT       Resume from checkpoint\n  --debug            Debug mode\n</code></pre>"},{"location":"user_guide/cli/#evaluate-evaluate-model","title":"<code>evaluate</code> - Evaluate Model","text":"<pre><code>frameworm evaluate [OPTIONS]\n\nOptions:\n  --config TEXT        Config file [required]\n  --checkpoint TEXT    Model checkpoint [required]\n  --metrics TEXT       Metrics to compute (default: fid,is)\n  --num-samples INT    Number of samples (default: 10000)\n</code></pre>"},{"location":"user_guide/cli/#search-hyperparameter-search","title":"<code>search</code> - Hyperparameter Search","text":"<pre><code>frameworm search [OPTIONS]\n\nOptions:\n  --config TEXT       Base config [required]\n  --space TEXT        Search space YAML [required]\n  --method [grid|random|bayesian]  Search method\n  --trials INT        Number of trials\n  --parallel INT      Parallel jobs\n</code></pre>"},{"location":"user_guide/cli/#export-export-model","title":"<code>export</code> - Export Model","text":"<pre><code>frameworm export CHECKPOINT [OPTIONS]\n\nOptions:\n  --format [torchscript|onnx|all]  Export format\n  --output TEXT                     Output directory\n  --quantize                        Also quantize model\n  --benchmark                       Benchmark exported model\n</code></pre>"},{"location":"user_guide/cli/#serve-serve-model","title":"<code>serve</code> - Serve Model","text":"<pre><code>frameworm serve MODEL_PATH [OPTIONS]\n\nOptions:\n  --port INT       Port to serve on (default: 8000)\n  --workers INT    Number of workers (default: 1)\n  --host TEXT      Host to bind to (default: 0.0.0.0)\n</code></pre>"},{"location":"user_guide/cli/#config-manage-configurations","title":"<code>config</code> - Manage Configurations","text":"<pre><code>frameworm config list            # List available configs\nframeworm config show CONFIG     # Show config contents\nframeworm config validate CONFIG # Validate config file\n</code></pre>"},{"location":"user_guide/cli/#examples","title":"Examples","text":""},{"location":"user_guide/cli/#complete-workflow","title":"Complete Workflow","text":"<pre><code># 1. Create project\nframeworm init gan-mnist --template gan\n\n# 2. Prepare data (manually)\n# ... download MNIST to data/\n\n# 3. Train\nframeworm train \\\n  --config configs/config.yaml \\\n  --gpus 0,1,2,3 \\\n  --experiment gan-baseline\n\n# 4. Hyperparameter search\nframeworm search \\\n  --config configs/config.yaml \\\n  --space configs/search_space.yaml \\\n  --method bayesian \\\n  --trials 50\n\n# 5. Evaluate best model\nframeworm evaluate \\\n  --checkpoint experiments/best/checkpoints/best.pt \\\n  --metrics fid,is \\\n  --num-samples 50000\n\n# 6. Export\nframeworm export \\\n  experiments/best/checkpoints/best.pt \\\n  --format onnx \\\n  --quantize\n\n# 7. Serve\nframeworm serve exported/model.pt --port 8000\n</code></pre>"},{"location":"user_guide/cli/#configuration-files","title":"Configuration Files","text":"<p>See Configuration Guide for details on config files.</p>"},{"location":"user_guide/cli/#environment-variables","title":"Environment Variables","text":"<pre><code>FRAMEWORM_DATA_DIR=/path/to/data\nFRAMEWORM_EXPERIMENT_DIR=/path/to/experiments\nFRAMEWORM_CHECKPOINT_DIR=/path/to/checkpoints\n</code></pre>"},{"location":"user_guide/configuration/","title":"Configuration System","text":""},{"location":"user_guide/configuration/#overview","title":"Overview","text":"<p>Frameworm uses a powerful YAML-based configuration system with support for: - Config inheritance - Environment variable interpolation - CLI overrides - Pydantic validation</p>"},{"location":"user_guide/configuration/#basic-usage","title":"Basic Usage","text":""},{"location":"user_guide/configuration/#loading-a-config","title":"Loading a Config","text":"<pre><code>from frameworm.core import Config\n\ncfg = Config('configs/model.yaml')\nprint(cfg.model.name)  # Access with dot notation\nprint(cfg['model']['name'])  # Or dict-style\n</code></pre>"},{"location":"user_guide/configuration/#config-inheritance","title":"Config Inheritance","text":"<p>Configs can inherit from other configs using the <code>_base_</code> key: <pre><code># configs/base.yaml\ntraining:\n  epochs: 100\n  batch_size: 32\n\n# configs/gan.yaml\n_base_: ./base.yaml\ntraining:\n  epochs: 200  # Override\nmodel:\n  type: gan  # Add new\n</code></pre></p> <p>Multiple levels of inheritance are supported.</p>"},{"location":"user_guide/configuration/#environment-variables","title":"Environment Variables","text":"<p>Use <code>${VAR_NAME}</code> syntax for environment variables: <pre><code>paths:\n  data_dir: ${DATA_ROOT}/images\n  output_dir: ./outputs/${EXPERIMENT_NAME}\n</code></pre></p>"},{"location":"user_guide/configuration/#cli-overrides","title":"CLI Overrides","text":"<p>Override config values from command line: <pre><code>cfg = Config.from_cli_args(\n    'config.yaml',\n    ['training.epochs=500', 'model.dim=256']\n)\n</code></pre></p>"},{"location":"user_guide/configuration/#validation","title":"Validation","text":"<p>Define validation schemas with Pydantic: <pre><code>from pydantic import BaseModel, Field\n\nclass ModelConfig(BaseModel):\n    name: str\n    dim: int = Field(gt=0)\n\ncfg = Config('model.yaml')\nvalidated = cfg.validate(ModelConfig)\n</code></pre></p>"},{"location":"user_guide/configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Use inheritance - Create a base config and extend it</li> <li>Validate configs - Define schemas for important configs</li> <li>Environment variables - For paths and secrets</li> <li>Freeze configs - After loading to prevent accidental modifications</li> <li>Dump configs - Save merged configs for reproducibility</li> </ol>"},{"location":"user_guide/configuration/#examples","title":"Examples","text":"<p>See <code>examples/config_examples.py</code> for more usage patterns.</p>"},{"location":"user_guide/dashboard/","title":"Web Dashboard","text":""},{"location":"user_guide/dashboard/#overview","title":"Overview","text":"<p>FRAMEWORM includes a web-based dashboard for experiment tracking, model management, and training monitoring.</p>"},{"location":"user_guide/dashboard/#launch-dashboard","title":"Launch Dashboard","text":"<pre><code>frameworm dashboard --port 8080\n</code></pre> <p>Then open http://localhost:8080 in your browser.</p>"},{"location":"user_guide/dashboard/#features","title":"Features","text":""},{"location":"user_guide/dashboard/#1-dashboard-home","title":"1. Dashboard Home","text":"<ul> <li>Overview of all experiments</li> <li>System resource usage</li> <li>Recent activity</li> </ul>"},{"location":"user_guide/dashboard/#2-experiments","title":"2. Experiments","text":"<ul> <li>List and filter experiments</li> <li>View experiment details</li> <li>Compare multiple experiments</li> <li>Visualize metrics</li> </ul>"},{"location":"user_guide/dashboard/#3-models","title":"3. Models","text":"<ul> <li>Model registry</li> <li>Export models (TorchScript, ONNX)</li> <li>Deploy models</li> <li>Model metadata</li> </ul>"},{"location":"user_guide/dashboard/#4-training-monitor","title":"4. Training Monitor","text":"<ul> <li>Start/stop training</li> <li>Real-time metrics</li> <li>Training logs</li> <li>Progress tracking</li> </ul>"},{"location":"user_guide/dashboard/#api","title":"API","text":"<p>The dashboard runs on FastAPI backend.</p> <p>API documentation: http://localhost:8080/docs</p>"},{"location":"user_guide/dashboard/#key-endpoints","title":"Key Endpoints","text":"<p>GET  /api/experiments           # List experiments GET  /api/experiments/{id}      # Get experiment POST /api/experiments           # Create experiment GET  /api/models                # List models POST /api/models/export         # Export model GET  /api/system/status         # System status WS   /api/training/stream       # Real-time training</p>"},{"location":"user_guide/dashboard/#development","title":"Development","text":""},{"location":"user_guide/dashboard/#frontend-development","title":"Frontend Development","text":"<pre><code>cd frameworm/ui/frontend\nnpm install\nnpm start  # Development server on port 3000\n</code></pre>"},{"location":"user_guide/dashboard/#backend-development","title":"Backend Development","text":"<pre><code>python -m frameworm.ui.api\n</code></pre>"},{"location":"user_guide/dashboard/#build-production-bundle","title":"Build Production Bundle","text":"<pre><code>./frameworm/ui/build_frontend.sh\n</code></pre>"},{"location":"user_guide/dashboard/#configuration","title":"Configuration","text":"<p>Set environment variables: <pre><code>export FRAMEWORM_EXPERIMENT_DIR=/path/to/experiments\nexport FRAMEWORM_CHECKPOINT_DIR=/path/to/checkpoints\n</code></pre></p>"},{"location":"user_guide/dashboard/#screenshots","title":"Screenshots","text":"<p>(Add screenshots of dashboard pages)</p>"},{"location":"user_guide/dashboard/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/dashboard/#port-already-in-use","title":"Port Already in Use","text":"<pre><code>frameworm dashboard --port 8081\n</code></pre>"},{"location":"user_guide/dashboard/#api-connection-issues","title":"API Connection Issues","text":"<p>Check that backend is running: <pre><code>curl http://localhost:8080/api/system/status\n</code></pre></p>"},{"location":"user_guide/dependency_graphs/","title":"Dependency Graphs","text":""},{"location":"user_guide/dependency_graphs/#overview","title":"Overview","text":"<p>Frameworm's dependency graph system allows you to define complex workflows where tasks have dependencies on other tasks.</p>"},{"location":"user_guide/dependency_graphs/#basic-usage","title":"Basic Usage","text":""},{"location":"user_guide/dependency_graphs/#creating-a-graph","title":"Creating a Graph","text":"<pre><code>from frameworm.graph import Graph, Node\n\n# Create graph\ngraph = Graph()\n\n# Add nodes\ngraph.add_node(Node(\"load\", fn=load_data))\ngraph.add_node(Node(\"process\", fn=process, depends_on=[\"load\"]))\ngraph.add_node(Node(\"train\", fn=train, depends_on=[\"process\"]))\n\n# Execute\nresults = graph.execute()\n</code></pre>"},{"location":"user_guide/dependency_graphs/#node-definition","title":"Node Definition","text":"<pre><code>node = Node(\n    node_id=\"my_step\",           # Unique identifier\n    fn=my_function,              # Function to execute\n    depends_on=[\"step1\", \"step2\"],  # Dependencies\n    description=\"My step\",       # Optional description\n    cache_result=True            # Enable caching\n)\n</code></pre>"},{"location":"user_guide/dependency_graphs/#advanced-features","title":"Advanced Features","text":""},{"location":"user_guide/dependency_graphs/#conditional-execution","title":"Conditional Execution","text":"<pre><code>from frameworm.graph import ConditionalNode\n\n# Only execute if condition is met\nnode = ConditionalNode(\n    \"conditional_step\",\n    fn=expensive_operation,\n    condition=lambda x: x &gt; threshold,\n    depends_on=[\"input\"]\n)\n</code></pre>"},{"location":"user_guide/dependency_graphs/#result-caching","title":"Result Caching","text":"<pre><code>from frameworm.graph import CachedGraph\n\n# Cache results to disk\ngraph = CachedGraph(cache_dir=\".cache\")\ngraph.add_node(Node(\"expensive\", fn=slow_function))\n\n# First run: executes function\nresults1 = graph.execute()\n\n# Second run: uses cached result!\nresults2 = graph.execute()\n</code></pre>"},{"location":"user_guide/dependency_graphs/#error-handling","title":"Error Handling","text":"<pre><code># Stop on first error (default)\nresults = graph.execute()\n\n# Continue even if nodes fail\nresults = graph.execute(continue_on_error=True)\n\n# Check which nodes failed\nsummary = graph.get_last_execution_summary()\nprint(summary['failed'])  # Number of failures\nprint(summary['errors'])  # Error details\n</code></pre>"},{"location":"user_guide/dependency_graphs/#pipeline-integration","title":"Pipeline Integration","text":"<pre><code>from frameworm.pipelines.base import GraphPipeline\n\n# Create graph-based pipeline\npipeline = GraphPipeline(config)\n\npipeline.add_step(\"load\", load_data)\npipeline.add_step(\"train\", train_model, depends_on=[\"load\"])\npipeline.add_step(\"eval\", evaluate, depends_on=[\"train\"])\n\n# Execute\nresults = pipeline.run()\n</code></pre>"},{"location":"user_guide/dependency_graphs/#visualization","title":"Visualization","text":""},{"location":"user_guide/dependency_graphs/#ascii-visualization","title":"ASCII Visualization","text":"<pre><code>from frameworm.graph.visualization import print_graph_ascii\n\nprint_graph_ascii(graph)\n</code></pre> <p>Output: Graph Structure: \u25cf load \u2193 process \u25cf process \u2191 load \u2193 train \u25cf train \u2191 process</p>"},{"location":"user_guide/dependency_graphs/#graphviz-visualization","title":"Graphviz Visualization","text":"<pre><code>from frameworm.graph.visualization import save_graph_image\n\n# Requires: pip install graphviz\nsave_graph_image(graph, \"my_graph.png\")\n</code></pre>"},{"location":"user_guide/dependency_graphs/#best-practices","title":"Best Practices","text":"<ol> <li>Use descriptive node IDs - Makes debugging easier</li> <li>Keep functions pure - Easier to cache and test</li> <li>Handle errors explicitly - Don't rely on continue_on_error</li> <li>Visualize complex graphs - Helps understand dependencies</li> <li>Cache expensive operations - Use CachedGraph for long-running tasks</li> <li>Test nodes individually - Before adding to graph</li> </ol>"},{"location":"user_guide/dependency_graphs/#examples","title":"Examples","text":"<p>See <code>examples/graph_pipeline.py</code> for complete working examples.</p>"},{"location":"user_guide/dependency_graphs/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/dependency_graphs/#cycle-detected","title":"Cycle Detected","text":"<p>CycleDetectedError: Cycle detected in dependency graph Cycle: a \u2192 b \u2192 c \u2192 a</p> <p>Solution: Remove one dependency to break the cycle.</p>"},{"location":"user_guide/dependency_graphs/#missing-dependency","title":"Missing Dependency","text":"<p>GraphError: Node 'b' depends on 'a' which doesn't exist</p> <p>Solution: Add the missing node or fix the dependency name.</p>"},{"location":"user_guide/deployment/","title":"Model Deployment","text":""},{"location":"user_guide/deployment/#overview","title":"Overview","text":"<p>Deploy FRAMEWORM models to production with export, serving, and containerization.</p>"},{"location":"user_guide/deployment/#export-models","title":"Export Models","text":""},{"location":"user_guide/deployment/#torchscript","title":"TorchScript","text":"<pre><code>from frameworm.deployment import ModelExporter\n\nexporter = ModelExporter(model, example_input)\nexporter.to_torchscript('model.pt', method='trace')\n</code></pre>"},{"location":"user_guide/deployment/#onnx","title":"ONNX","text":"<pre><code>exporter.to_onnx('model.onnx', opset_version=14)\n</code></pre>"},{"location":"user_guide/deployment/#quantization","title":"Quantization","text":"<pre><code>quantized = exporter.quantize('model_quant.pt', method='dynamic')\n</code></pre>"},{"location":"user_guide/deployment/#serve-models","title":"Serve Models","text":""},{"location":"user_guide/deployment/#fastapi-server","title":"FastAPI Server","text":"<pre><code>from frameworm.deployment import ModelServer\n\nserver = ModelServer('model.pt')\nserver.run(host='0.0.0.0', port=8000)\n</code></pre> <p>Or via CLI: <pre><code>python -m frameworm.deployment.server --model model.pt --port 8000\n</code></pre></p>"},{"location":"user_guide/deployment/#api-endpoints","title":"API Endpoints","text":"<ul> <li><code>POST /predict</code> - JSON prediction</li> <li><code>POST /predict/image</code> - Image prediction</li> <li><code>POST /predict/batch</code> - Batch prediction</li> <li><code>GET /health</code> - Health check</li> <li><code>GET /docs</code> - API documentation</li> </ul>"},{"location":"user_guide/deployment/#example-request","title":"Example Request","text":"<pre><code>curl -X POST http://localhost:8000/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"data\": [[1.0, 2.0, 3.0, 4.0, 5.0]]}'\n</code></pre>"},{"location":"user_guide/deployment/#docker-deployment","title":"Docker Deployment","text":""},{"location":"user_guide/deployment/#build-image","title":"Build Image","text":"<pre><code>docker build -t model-server .\n</code></pre>"},{"location":"user_guide/deployment/#run-container","title":"Run Container","text":"<pre><code>docker run -p 8000:8000 -v $(pwd)/models:/app/models model-server\n</code></pre>"},{"location":"user_guide/deployment/#docker-compose","title":"Docker Compose","text":"<pre><code>docker-compose up -d\n</code></pre>"},{"location":"user_guide/deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"user_guide/deployment/#deploy","title":"Deploy","text":"<pre><code>kubectl apply -f k8s/deployment.yaml\n</code></pre>"},{"location":"user_guide/deployment/#check-status","title":"Check Status","text":"<pre><code>kubectl get pods\nkubectl get services\n</code></pre>"},{"location":"user_guide/deployment/#scale","title":"Scale","text":"<pre><code>kubectl scale deployment model-server --replicas=5\n</code></pre>"},{"location":"user_guide/deployment/#production-best-practices","title":"Production Best Practices","text":"<ol> <li>Use quantization for faster inference</li> <li>Enable caching for repeated requests</li> <li>Set up monitoring (Prometheus/Grafana)</li> <li>Use load balancing (nginx/K8s service)</li> <li>Implement rate limiting</li> <li>Add authentication for sensitive models</li> </ol>"},{"location":"user_guide/deployment/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user_guide/deployment/#batch-processing","title":"Batch Processing","text":"<p>Process multiple samples together: <pre><code># Better: batch of 32\noutput = model(batch_of_32)\n\n# Slower: one at a time\nfor sample in samples:\n    output = model(sample)\n</code></pre></p>"},{"location":"user_guide/deployment/#onnx-runtime","title":"ONNX Runtime","text":"<p>2-5x faster inference: <pre><code>from frameworm.deployment import ONNXInferenceSession\n\nsession = ONNXInferenceSession('model.onnx')\noutput = session.run(input_data)\n</code></pre></p>"},{"location":"user_guide/deployment/#gpu-inference","title":"GPU Inference","text":"<p>Enable CUDA for faster serving: <pre><code>server = ModelServer('model.pt', device='cuda')\n</code></pre></p>"},{"location":"user_guide/distributed-training/","title":"Distributed Training Guide","text":"<p>Scale training to multiple GPUs and machines.</p>"},{"location":"user_guide/distributed-training/#single-machine-multi-gpu","title":"Single-Machine Multi-GPU","text":""},{"location":"user_guide/distributed-training/#dataparallel-simplest","title":"DataParallel (Simplest)","text":"<pre><code>from frameworm import Trainer\n\ntrainer = Trainer(model, optimizer)\ntrainer.enable_data_parallel(device_ids=[0, 1, 2, 3])\ntrainer.train(train_loader, val_loader)\n</code></pre> <p>Pros: - One line of code - No process management</p> <p>Cons: - GIL bottleneck - Unbalanced GPU usage - Slower than DDP</p> <p>Use when: Quick prototyping, &lt; 4 GPUs</p>"},{"location":"user_guide/distributed-training/#distributeddataparallel-recommended","title":"DistributedDataParallel (Recommended)","text":"<pre><code>import torch.multiprocessing as mp\nfrom frameworm.distributed import DDPTrainer, setup_ddp\n\ndef train_worker(rank, world_size):\n    # Setup DDP\n    setup_ddp(rank, world_size)\n\n    # Create model and trainer\n    trainer = DDPTrainer(model, optimizer, rank, world_size)\n\n    # Train\n    trainer.train(train_loader, val_loader, epochs=100)\n\n    # Cleanup\n    trainer.cleanup()\n\nif __name__ == '__main__':\n    world_size = 4  # Number of GPUs\n    mp.spawn(train_worker, args=(world_size,), nprocs=world_size, join=True)\n</code></pre> <p>Pros: - Fastest for multi-GPU - Balanced GPU usage - Scales to 100s of GPUs</p> <p>Cons: - More complex setup - Multi-process</p> <p>Use when: &gt; 4 GPUs, production training</p>"},{"location":"user_guide/distributed-training/#multi-machine-training","title":"Multi-Machine Training","text":""},{"location":"user_guide/distributed-training/#setup","title":"Setup","text":"<p>Node 0 (master): <pre><code>export MASTER_ADDR=192.168.1.100\nexport MASTER_PORT=12355\nexport RANK=0\nexport WORLD_SIZE=8  # Total GPUs across all nodes\n\nframeworm train --config config.yaml --distributed\n</code></pre></p> <p>Node 1 (worker): <pre><code>export MASTER_ADDR=192.168.1.100\nexport MASTER_PORT=12355\nexport RANK=4  # Offset by number of GPUs on previous nodes\nexport WORLD_SIZE=8\n\nframeworm train --config config.yaml --distributed\n</code></pre></p>"},{"location":"user_guide/distributed-training/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user_guide/distributed-training/#mixed-precision","title":"Mixed Precision","text":"<pre><code>trainer.enable_mixed_precision()\n</code></pre> <p>Speedup: 2-3x on modern GPUs (V100, A100)</p>"},{"location":"user_guide/distributed-training/#gradient-compression","title":"Gradient Compression","text":"<pre><code>from frameworm.distributed import enable_gradient_compression\n\nenable_gradient_compression(ddp_model, rank)\n</code></pre> <p>Bandwidth reduction: ~10x</p>"},{"location":"user_guide/distributed-training/#optimal-batch-size","title":"Optimal Batch Size","text":"GPUs Batch Size Effective Batch Size 1 128 128 4 128 512 8 128 1024 16 64 1024 <p>Rule: Keep effective batch size constant, adjust learning rate.</p>"},{"location":"user_guide/distributed-training/#troubleshooting","title":"Troubleshooting","text":"<p>NCCL Timeout: <pre><code>export NCCL_TIMEOUT=1800  # 30 minutes\n</code></pre></p> <p>Unbalanced GPUs: - Check data loading is distributed - Verify batch sizes are equal - Monitor with <code>nvidia-smi</code></p> <p>Out of Memory: - Reduce batch size - Enable gradient checkpointing - Use gradient accumulation</p>"},{"location":"user_guide/distributed_optimization/","title":"Distributed Training Optimization","text":""},{"location":"user_guide/distributed_optimization/#performance-optimization-guide","title":"Performance Optimization Guide","text":""},{"location":"user_guide/distributed_optimization/#1-mixed-precision-training","title":"1. Mixed Precision Training","text":"<p>Speedup: 2-3x faster Memory: 50% reduction <pre><code>trainer = DistributedTrainer(\n    model,\n    optimizer,\n    use_amp=True  # Enable mixed precision\n)\n</code></pre></p> <p>When to use: - NVIDIA GPU with Tensor Cores (Volta, Turing, Ampere) - Large models - Want faster training</p>"},{"location":"user_guide/distributed_optimization/#2-gradient-accumulation","title":"2. Gradient Accumulation","text":"<p>Effect: Larger effective batch size Memory: Reduced memory usage <pre><code>trainer = DistributedTrainer(\n    model,\n    optimizer,\n    gradient_accumulation_steps=4\n)\n\n# Effective batch size = batch_size \u00d7 world_size \u00d7 4\n</code></pre></p> <p>When to use: - Model doesn't fit with desired batch size - Simulating larger batches - Limited GPU memory</p>"},{"location":"user_guide/distributed_optimization/#3-optimized-data-loading","title":"3. Optimized Data Loading","text":"<pre><code>from frameworm.distributed import OptimizedDataLoader\n\nloader = OptimizedDataLoader.create(\n    dataset,\n    batch_size=128,\n    num_workers=4,      # Parallel data loading\n    pin_memory=True,    # Faster GPU transfer\n    prefetch_factor=2,  # Prefetch batches\n    persistent_workers=True  # Reuse workers\n)\n</code></pre> <p>Auto-configuration: <pre><code># Automatically picks optimal settings\nloader = OptimizedDataLoader.create(dataset, batch_size=128)\n</code></pre></p>"},{"location":"user_guide/distributed_optimization/#4-efficient-batch-size","title":"4. Efficient Batch Size","text":"<p>Rule of thumb: - Start with largest batch size that fits - Typical: 32-256 per GPU - Use gradient accumulation for larger effective batch</p> <p>Find optimal batch size: <pre><code># Binary search for max batch size\nfor batch_size in [32, 64, 128, 256, 512]:\n    try:\n        trainer.train(get_loader(batch_size), epochs=1)\n        print(f\"Batch size {batch_size}: OK\")\n    except RuntimeError:  # OOM\n        print(f\"Batch size {batch_size}: Too large\")\n        break\n</code></pre></p>"},{"location":"user_guide/distributed_optimization/#profiling-performance","title":"Profiling Performance","text":""},{"location":"user_guide/distributed_optimization/#basic-profiling","title":"Basic Profiling","text":"<pre><code>from frameworm.distributed import PerformanceProfiler\n\nprofiler = PerformanceProfiler()\n\nfor batch in train_loader:\n    with profiler.profile('step'):\n        with profiler.profile('forward'):\n            loss = model(batch)\n\n        with profiler.profile('backward'):\n            loss.backward()\n\n        with profiler.profile('optimizer'):\n            optimizer.step()\n\n    profiler.record_gpu_memory()\n\nprofiler.print_summary()\n</code></pre>"},{"location":"user_guide/distributed_optimization/#identify-bottlenecks","title":"Identify Bottlenecks","text":"<p>Data loading bottleneck: Data Loading: 50ms Percent of step: 40%  # Too high!</p> <p>Solution: - Increase num_workers - Use pin_memory - Simplify data transforms</p> <p>GPU underutilization: Step Time: 100ms Forward: 30ms Backward: 30ms Optimizer: 5ms Data: 5ms 30ms unaccounted = communication overhead</p> <p>Solution: - Use gradient bucketing - Enable gradient compression - Check network bandwidth</p>"},{"location":"user_guide/distributed_optimization/#communication-optimization","title":"Communication Optimization","text":""},{"location":"user_guide/distributed_optimization/#gradient-bucketing","title":"Gradient Bucketing","text":"<p>Automatically enabled in DDP. Adjustable: <pre><code>from torch.nn.parallel import DistributedDataParallel as DDP\n\nmodel = DDP(\n    model,\n    bucket_cap_mb=25,  # Default: 25MB\n)\n</code></pre></p>"},{"location":"user_guide/distributed_optimization/#overlap-computation-and-communication","title":"Overlap Computation and Communication","text":"<p>Automatically handled by DDP. Ensure: - Use NCCL backend - Contiguous parameter layout - Reasonable model size</p>"},{"location":"user_guide/distributed_optimization/#multi-node-optimization","title":"Multi-Node Optimization","text":""},{"location":"user_guide/distributed_optimization/#network-configuration","title":"Network Configuration","text":"<ol> <li>InfiniBand: Best performance</li> <li>10GbE+: Good for small models</li> <li>1GbE: Avoid for multi-node</li> </ol>"},{"location":"user_guide/distributed_optimization/#reduce-communication","title":"Reduce Communication","text":"<pre><code># Use gradient accumulation\ntrainer = DistributedTrainer(\n    model,\n    optimizer,\n    gradient_accumulation_steps=8  # Fewer syncs\n)\n</code></pre>"},{"location":"user_guide/distributed_optimization/#performance-targets","title":"Performance Targets","text":"Configuration Expected Speedup Single GPU 1.0x (baseline) + Mixed Precision 2-3x + 2 GPUs (DDP) 1.8-1.9x per GPU + 4 GPUs (DDP) 3.5-3.8x total + 8 GPUs (DDP) 7.0-7.5x total"},{"location":"user_guide/distributed_optimization/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/distributed_optimization/#slow-training","title":"Slow Training","text":"<p>Check: 1. GPU utilization (<code>nvidia-smi</code>) 2. Data loading time (profiler) 3. Batch size (too small?) 4. Number of workers</p>"},{"location":"user_guide/distributed_optimization/#out-of-memory","title":"Out of Memory","text":"<p>Solutions: 1. Reduce batch size 2. Enable gradient accumulation 3. Use mixed precision 4. Enable gradient checkpointing</p>"},{"location":"user_guide/distributed_optimization/#poor-scaling","title":"Poor Scaling","text":"<p>Check: 1. Communication overhead (profiler) 2. Batch size (too small for multi-GPU?) 3. Model size (too small = overhead dominates) 4. Network bandwidth (multi-node)</p>"},{"location":"user_guide/distributed_optimization/#best-practices","title":"Best Practices","text":"<ol> <li>Always profile first - Know your bottleneck</li> <li>Use mixed precision - Almost always beneficial</li> <li>Optimize data loading - Prevent GPU starvation</li> <li>Scale batch size - With number of GPUs</li> <li>Monitor utilization - GPU should be &gt;90%</li> <li>Benchmark - Test before production runs</li> </ol>"},{"location":"user_guide/distributed_optimization/#example-optimal-configuration","title":"Example: Optimal Configuration","text":"<pre><code>from frameworm.distributed import DistributedTrainer, OptimizedDataLoader\n\n# Data\ntrain_loader = OptimizedDataLoader.create(\n    dataset,\n    batch_size=128,  # Per GPU\n    num_workers=4,\n    pin_memory=True\n)\n\n# Model\ntrainer = DistributedTrainer(\n    model,\n    optimizer,\n    backend='nccl',\n    use_amp=True,                    # 2-3x speedup\n    gradient_accumulation_steps=2,   # 2x effective batch\n    find_unused_parameters=False     # Faster\n)\n\n# Train\ntrainer.train(train_loader, val_loader)\n\n# Expected: ~10x faster than single GPU baseline\n</code></pre>"},{"location":"user_guide/distributed_training/","title":"Distributed Training","text":""},{"location":"user_guide/distributed_training/#overview","title":"Overview","text":"<p>Frameworm supports distributed training for faster training on multiple GPUs and machines.</p>"},{"location":"user_guide/distributed_training/#training-modes","title":"Training Modes","text":""},{"location":"user_guide/distributed_training/#1-single-gpu-baseline","title":"1. Single-GPU (Baseline)","text":"<pre><code>from frameworm.training import Trainer\n\ntrainer = Trainer(model, optimizer, device='cuda:0')\ntrainer.train(train_loader, val_loader)\n</code></pre>"},{"location":"user_guide/distributed_training/#2-dataparallel-simple-multi-gpu","title":"2. DataParallel (Simple Multi-GPU)","text":"<pre><code>from frameworm.distributed import DataParallelTrainer\n\n# Wrap model\nmodel = DataParallelTrainer.wrap(model)\n\n# Train normally\ntrainer = Trainer(model, optimizer, device='cuda:0')\ntrainer.train(train_loader, val_loader)\n</code></pre> <p>Pros: Simple, single process Cons: Less efficient, GIL bottleneck</p>"},{"location":"user_guide/distributed_training/#3-distributeddataparallel-recommended","title":"3. DistributedDataParallel (Recommended)","text":"<pre><code>from frameworm.distributed import DistributedTrainer\n\n# Automatically handles DDP\ntrainer = DistributedTrainer(model, optimizer, backend='nccl')\ntrainer.train(train_loader, val_loader)\n</code></pre> <p>Pros: Efficient, scales well Cons: Multi-process setup</p>"},{"location":"user_guide/distributed_training/#single-machine-multi-gpu","title":"Single-Machine Multi-GPU","text":""},{"location":"user_guide/distributed_training/#automatic-launch","title":"Automatic Launch","text":"<pre><code>from frameworm.distributed.trainer import launch_distributed\n\ndef train_fn(rank, world_size):\n    # Setup\n    setup_distributed()\n\n    # Train\n    trainer = DistributedTrainer(model, optimizer)\n    trainer.train(train_loader, val_loader)\n\n    # Cleanup\n    cleanup_distributed()\n\n# Launch on all GPUs\nlaunch_distributed(train_fn, nprocs=torch.cuda.device_count())\n</code></pre>"},{"location":"user_guide/distributed_training/#manual-launch-with-torchrun","title":"Manual Launch with torchrun","text":"<pre><code># Using torchrun (PyTorch 1.9+)\ntorchrun --nproc_per_node=4 train.py\n\n# Or older torch.distributed.launch\npython -m torch.distributed.launch --nproc_per_node=4 train.py\n</code></pre>"},{"location":"user_guide/distributed_training/#multi-node-training","title":"Multi-Node Training","text":""},{"location":"user_guide/distributed_training/#node-configuration","title":"Node Configuration","text":"<p>Node 0 (master): <pre><code>export MASTER_ADDR=192.168.1.1\nexport MASTER_PORT=29500\nexport WORLD_SIZE=8  # Total processes\nexport RANK=0\npython train.py\n</code></pre></p> <p>Node 1: <pre><code>export MASTER_ADDR=192.168.1.1\nexport MASTER_PORT=29500\nexport WORLD_SIZE=8\nexport RANK=4  # Offset by node0's GPU count\npython train.py\n</code></pre></p>"},{"location":"user_guide/distributed_training/#training-script","title":"Training Script","text":"<pre><code>from frameworm.distributed import setup_distributed, DistributedTrainer\n\n# Setup from environment variables\nsetup_distributed()\n\n# Train\ntrainer = DistributedTrainer(model, optimizer)\ntrainer.train(train_loader, val_loader)\n</code></pre>"},{"location":"user_guide/distributed_training/#data-loading","title":"Data Loading","text":""},{"location":"user_guide/distributed_training/#distributed-sampler","title":"Distributed Sampler","text":"<p>Automatically used by DistributedTrainer: <pre><code># Manual usage\nfrom frameworm.distributed import DistributedSampler\n\nsampler = DistributedSampler(dataset, shuffle=True)\nloader = DataLoader(dataset, sampler=sampler, batch_size=64)\n\n# Set epoch for proper shuffling\nfor epoch in range(epochs):\n    sampler.set_epoch(epoch)\n    for batch in loader:\n        # Training...\n</code></pre></p>"},{"location":"user_guide/distributed_training/#batch-size","title":"Batch Size","text":"<p>Important: Batch size is PER PROCESS. <pre><code># Effective batch size = batch_size \u00d7 world_size\nbatch_size = 32  # Per GPU\nworld_size = 4   # 4 GPUs\n# Total effective batch size = 128\n</code></pre></p>"},{"location":"user_guide/distributed_training/#checkpointing","title":"Checkpointing","text":"<p>Only master process saves: <pre><code>trainer = DistributedTrainer(model, optimizer)\ntrainer.train(train_loader, val_loader)\n\n# Automatically saves only from rank 0\ntrainer.save_checkpoint('checkpoint.pt')\n\n# All processes load\ntrainer.load_checkpoint('checkpoint.pt')\n</code></pre></p>"},{"location":"user_guide/distributed_training/#metric-aggregation","title":"Metric Aggregation","text":"<p>Metrics automatically averaged across processes: <pre><code># Each process computes local metrics\n# DistributedTrainer averages across all processes\ntrainer.train(train_loader, val_loader)\n\n# Final metrics are averaged\nprint(trainer.state.val_metrics)  # Already aggregated\n</code></pre></p>"},{"location":"user_guide/distributed_training/#communication-backends","title":"Communication Backends","text":""},{"location":"user_guide/distributed_training/#nccl-nvidia","title":"NCCL (NVIDIA)","text":"<p><pre><code>trainer = DistributedTrainer(model, optimizer, backend='nccl')\n</code></pre> - Best for: NVIDIA GPUs - Supports: CUDA only - Performance: Fastest</p>"},{"location":"user_guide/distributed_training/#gloo","title":"Gloo","text":"<p><pre><code>trainer = DistributedTrainer(model, optimizer, backend='gloo')\n</code></pre> - Best for: CPU or mixed CPU/GPU - Supports: CPU and CUDA - Performance: Good</p>"},{"location":"user_guide/distributed_training/#mpi","title":"MPI","text":"<p><pre><code>trainer = DistributedTrainer(model, optimizer, backend='mpi')\n</code></pre> - Best for: HPC clusters - Supports: CPU and CUDA - Performance: Good</p>"},{"location":"user_guide/distributed_training/#best-practices","title":"Best Practices","text":"<ol> <li>Use NCCL for GPUs - Fastest backend</li> <li>Set epoch in sampler - For proper shuffling</li> <li>Scale learning rate - lr \u00d7 world_size for large batches</li> <li>Gradient accumulation - For even larger effective batches</li> <li>Warmup - Help large batch training converge</li> </ol>"},{"location":"user_guide/distributed_training/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/distributed_training/#nccl-timeout","title":"NCCL Timeout","text":"<pre><code>import os\nos.environ['NCCL_TIMEOUT'] = '1800'  # 30 minutes\n</code></pre>"},{"location":"user_guide/distributed_training/#find-unused-parameters-error","title":"Find Unused Parameters Error","text":"<pre><code>trainer = DistributedTrainer(\n    model,\n    optimizer,\n    find_unused_parameters=True  # For dynamic graphs\n)\n</code></pre>"},{"location":"user_guide/distributed_training/#hangs-at-initialization","title":"Hangs at Initialization","text":"<pre><code># Check firewall\nsudo ufw allow 29500\n\n# Use different port\nexport MASTER_PORT=29501\n</code></pre>"},{"location":"user_guide/distributed_training/#examples","title":"Examples","text":"<p>See <code>examples/distributed_training_example.py</code> for complete examples.</p>"},{"location":"user_guide/error_handling/","title":"Error Handling","text":""},{"location":"user_guide/error_handling/#overview","title":"Overview","text":"<p>Frameworm provides helpful, actionable error messages that explain: - What went wrong - Why it happened - How to fix it - Where to learn more</p>"},{"location":"user_guide/error_handling/#error-types","title":"Error Types","text":""},{"location":"user_guide/error_handling/#configuration-errors","title":"Configuration Errors","text":"<p>ConfigNotFoundError - Config file not found <pre><code>try:\n    cfg = Config(\"missing.yaml\")\nexcept ConfigNotFoundError as e:\n    print(e)  # Helpful message with suggestions\n</code></pre></p> <p>ConfigValidationError - Invalid config value <pre><code># Triggered when required fields missing or values invalid\n</code></pre></p>"},{"location":"user_guide/error_handling/#model-errors","title":"Model Errors","text":"<p>DimensionMismatchError - Tensor shape mismatch <pre><code># Provides analysis of dimension mismatch\n# Suggests fixes (reshape, unsqueeze, etc.)\n</code></pre></p> <p>ModelNotFoundError - Model not in registry <pre><code>try:\n    model = get_model(\"nonexistent\")\nexcept ModelNotFoundError as e:\n    print(e)  # Shows available models\n</code></pre></p>"},{"location":"user_guide/error_handling/#plugin-errors","title":"Plugin Errors","text":"<p>PluginValidationError - Plugin missing required methods <pre><code># Shows which methods are missing\n# Suggests how to implement them\n</code></pre></p>"},{"location":"user_guide/error_handling/#example-error-messages","title":"Example Error Messages","text":""},{"location":"user_guide/error_handling/#dimension-mismatch","title":"Dimension Mismatch","text":"<p>DimensionMismatchError: Tensor dimension mismatch Details: Expected shape: (4, 100, 1, 1) Received shape: (4, 100) Layer: generator.main[0] Likely Causes:</p> <p>Input has 2 fewer dimension(s) than expected</p> <p>Suggested Fixes: \u2192 Add spatial dimensions: x.unsqueeze(-1).unsqueeze(-1) \u2192 Or reshape: x.view(batch, channels, 1, 1)</p>"},{"location":"user_guide/error_handling/#model-not-found","title":"Model Not Found","text":"<p>ModelNotFoundError: Model 'my-model' not found in registry Details: Requested: my-model Available models: dcgan, stylegan2, vae Suggested Fixes: \u2192 List all models: frameworm list-models \u2192 Re-discover plugins: discover_plugins(force=True)</p>"},{"location":"user_guide/error_handling/#best-practices","title":"Best Practices","text":"<ol> <li>Don't catch errors silently - Let them propagate</li> <li>Read the suggestions - They're usually right</li> <li>Check documentation links - Learn the concepts</li> <li>Use the debug tools - They help diagnose issues</li> </ol>"},{"location":"user_guide/error_handling/#custom-errors","title":"Custom Errors","text":"<p>Create custom errors for your plugins: ```python from frameworm.core.exceptions import FramewormError</p> <p>class MyCustomError(FramewormError):     def init(self, message, kwargs):         super().init(message, kwargs)</p> <pre><code>    self.add_cause(\"Your cause here\")\n    self.add_suggestion(\"Your fix here\")\n    self.set_doc_link(\"your-docs-url\")\n</code></pre>"},{"location":"user_guide/experiment_tracking/","title":"Experiment Tracking","text":""},{"location":"user_guide/experiment_tracking/#overview","title":"Overview","text":"<p>Frameworm provides comprehensive experiment tracking to manage, compare, and reproduce experiments.</p>"},{"location":"user_guide/experiment_tracking/#basic-usage","title":"Basic Usage","text":""},{"location":"user_guide/experiment_tracking/#creating-an-experiment","title":"Creating an Experiment","text":"<pre><code>from frameworm.experiment import Experiment\n\nexp = Experiment(\n    name=\"my-experiment\",\n    config=config,\n    description=\"Testing new architecture\",\n    tags=[\"vae\", \"mnist\", \"baseline\"],\n    root_dir=\"experiments\"\n)\n\nwith exp:\n    # Your training code\n    trainer.set_experiment(exp)\n    trainer.train(train_loader, val_loader)\n\n# Automatically tracks:\n# - Config\n# - Metrics\n# - Git version\n# - Artifacts\n</code></pre>"},{"location":"user_guide/experiment_tracking/#integration-with-trainer","title":"Integration with Trainer","text":"<pre><code>trainer = Trainer(model, optimizer)\ntrainer.set_experiment(exp)\n\n# Metrics automatically logged\ntrainer.train(train_loader, val_loader)\n</code></pre>"},{"location":"user_guide/experiment_tracking/#managing-experiments","title":"Managing Experiments","text":""},{"location":"user_guide/experiment_tracking/#list-experiments","title":"List Experiments","text":"<pre><code>from frameworm.experiment import ExperimentManager\n\nmanager = ExperimentManager('experiments')\n\n# List all experiments\ndf = manager.list_experiments()\n\n# Filter by status\ndf = manager.list_experiments(status='completed')\n\n# Filter by tags\ndf = manager.list_experiments(tags=['vae', 'mnist'])\n</code></pre>"},{"location":"user_guide/experiment_tracking/#compare-experiments","title":"Compare Experiments","text":"<pre><code># Compare multiple experiments\ncomparison = manager.compare_experiments(\n    ['exp_001', 'exp_002', 'exp_003'],\n    metrics=['loss', 'val_loss']\n)\n\nprint(comparison[['name', 'loss', 'val_loss']])\n</code></pre>"},{"location":"user_guide/experiment_tracking/#search-experiments","title":"Search Experiments","text":"<pre><code># Search by config\nresults = manager.search_experiments(\n    config_filter={'training.lr': 0.001}\n)\n\n# Search by metrics\nresults = manager.search_experiments(\n    metric_filter={'val_loss': ('&lt;=', 0.5)}\n)\n</code></pre>"},{"location":"user_guide/experiment_tracking/#visualization","title":"Visualization","text":""},{"location":"user_guide/experiment_tracking/#plot-metric-comparison","title":"Plot Metric Comparison","text":"<pre><code>from frameworm.experiment.visualization import plot_metric_comparison\n\nplot_metric_comparison(\n    manager,\n    ['exp_001', 'exp_002', 'exp_003'],\n    'loss',\n    save_path='comparison.png'\n)\n</code></pre>"},{"location":"user_guide/experiment_tracking/#plot-multiple-metrics","title":"Plot Multiple Metrics","text":"<pre><code>from frameworm.experiment.visualization import plot_multiple_metrics\n\nplot_multiple_metrics(\n    manager,\n    'exp_001',\n    ['loss', 'val_loss', 'kl_div'],\n    save_path='metrics.png'\n)\n</code></pre>"},{"location":"user_guide/experiment_tracking/#cli-interface","title":"CLI Interface","text":""},{"location":"user_guide/experiment_tracking/#list-experiments_1","title":"List Experiments","text":"<pre><code>python -m frameworm.experiment.cli list\npython -m frameworm.experiment.cli list --status completed\n</code></pre>"},{"location":"user_guide/experiment_tracking/#show-experiment","title":"Show Experiment","text":"<pre><code>python -m frameworm.experiment.cli show exp_001\n</code></pre>"},{"location":"user_guide/experiment_tracking/#compare-experiments_1","title":"Compare Experiments","text":"<pre><code>python -m frameworm.experiment.cli compare exp_001 exp_002 exp_003\n</code></pre>"},{"location":"user_guide/experiment_tracking/#plot-metrics","title":"Plot Metrics","text":"<pre><code>python -m frameworm.experiment.cli plot exp_001 exp_002 loss --output loss.png\n</code></pre>"},{"location":"user_guide/experiment_tracking/#delete-experiment","title":"Delete Experiment","text":"<pre><code>python -m frameworm.experiment.cli delete exp_001\n</code></pre>"},{"location":"user_guide/experiment_tracking/#best-practices","title":"Best Practices","text":"<ol> <li>Use Descriptive Names - Easy to identify later</li> <li>Add Tags - Enable filtering and organization</li> <li>Track Everything - Config, metrics, git version</li> <li>Compare Often - Find what works</li> <li>Clean Up - Delete failed/test experiments</li> </ol>"},{"location":"user_guide/experiment_tracking/#storage-structure","title":"Storage Structure","text":"<p>experiments/ \u251c\u2500\u2500 exp_001_vae_baseline/ \u2502   \u251c\u2500\u2500 config.yaml          # Saved configuration \u2502   \u251c\u2500\u2500 metadata.json        # Experiment metadata \u2502   \u251c\u2500\u2500 checkpoints/         # Model checkpoints \u2502   \u251c\u2500\u2500 logs/               # Training logs \u2502   \u2514\u2500\u2500 artifacts/          # Additional files \u2514\u2500\u2500 experiments.db          # SQLite database</p>"},{"location":"user_guide/experiment_tracking/#reproducibility","title":"Reproducibility","text":"<p>Every experiment automatically tracks: - Complete configuration - Git commit hash - Git dirty status (uncommitted changes) - All hyperparameters - Environment info - Metrics history - Artifacts</p> <p>This enables perfect reproducibility of any experiment.</p>"},{"location":"user_guide/hyperparameter_search/","title":"Hyperparameter Search","text":""},{"location":"user_guide/hyperparameter_search/#overview","title":"Overview","text":"<p>Frameworm provides systematic hyperparameter search with multiple strategies.</p>"},{"location":"user_guide/hyperparameter_search/#search-spaces","title":"Search Spaces","text":""},{"location":"user_guide/hyperparameter_search/#define-search-space","title":"Define Search Space","text":"<pre><code>from frameworm.search.space import Real, Integer, Categorical\n\nsearch_space = {\n    'training.lr': Real(1e-5, 1e-2, log=True),\n    'training.batch_size': Integer(32, 256, log=True),\n    'optimizer': Categorical(['adam', 'sgd', 'rmsprop']),\n    'model.hidden_dim': Integer(128, 512)\n}\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#space-types","title":"Space Types","text":"<p>Categorical - Discrete choices: <pre><code>Categorical(['adam', 'sgd', 'rmsprop'])\n</code></pre></p> <p>Integer - Integer values: <pre><code>Integer(32, 256, log=True)  # Sample in log space\nInteger(1, 10, log=False)   # Sample linearly\n</code></pre></p> <p>Real - Continuous values: <pre><code>Real(1e-5, 1e-2, log=True)  # Sample in log space\nReal(0.0, 1.0, log=False)   # Sample linearly\n</code></pre></p>"},{"location":"user_guide/hyperparameter_search/#grid-search","title":"Grid Search","text":"<p>Exhaustive search over all combinations. <pre><code>from frameworm.search import GridSearch\n\nsearch = GridSearch(\n    base_config=config,\n    search_space={\n        'training.lr': [0.001, 0.0001, 0.00001],\n        'training.batch_size': [64, 128, 256]\n    },\n    metric='val_loss',\n    mode='min'\n)\n\nbest_config, best_score = search.run(train_fn)\n</code></pre></p> <p>When to use: - Small search space (&lt; 100 combinations) - Want exhaustive coverage - Discrete parameters</p>"},{"location":"user_guide/hyperparameter_search/#random-search","title":"Random Search","text":"<p>Sample random configurations. <pre><code>from frameworm.search import RandomSearch\nfrom frameworm.search.space import Real, Integer\n\nsearch = RandomSearch(\n    base_config=config,\n    search_space={\n        'training.lr': Real(1e-5, 1e-2, log=True),\n        'training.batch_size': Integer(32, 256, log=True)\n    },\n    metric='val_loss',\n    mode='min',\n    n_trials=50\n)\n\nbest_config, best_score = search.run(train_fn)\n</code></pre></p> <p>When to use: - Large search space - Continuous parameters - Limited compute budget - Often more efficient than grid search</p>"},{"location":"user_guide/hyperparameter_search/#bayesian-optimization","title":"Bayesian Optimization","text":"<p>Most sample-efficient method for expensive evaluations. <pre><code>from frameworm.search import BayesianSearch\nfrom frameworm.search.space import Real, Integer\n\nsearch = BayesianSearch(\n    base_config=config,\n    search_space={\n        'training.lr': Real(1e-5, 1e-2, log=True),\n        'training.batch_size': Integer(32, 256, log=True),\n        'model.hidden_dim': Integer(128, 512)\n    },\n    metric='val_loss',\n    mode='min',\n    n_trials=50,\n    n_initial_points=10,\n    acquisition='ei'  # Expected Improvement\n)\n\nbest_config, best_score = search.run(train_fn)\n</code></pre></p> <p>When to use: - Training is expensive (&gt; 10 min/trial) - &lt; 100 trials budget - Need sample efficiency - Sequential evaluation okay</p> <p>Acquisition Functions: - <code>'ei'</code>: Expected Improvement (default, balanced) - <code>'lcb'</code>: Lower Confidence Bound (more exploration) - <code>'pi'</code>: Probability of Improvement (more exploitation)</p>"},{"location":"user_guide/hyperparameter_search/#comparison-guide","title":"Comparison Guide","text":""},{"location":"user_guide/hyperparameter_search/#grid-vs-random-vs-bayesian","title":"Grid vs Random vs Bayesian","text":"Aspect Grid Random Bayesian Sample Efficiency Low Medium High Parallelizable \u2705 Yes \u2705 Yes \u274c Sequential Setup Complexity Low Low Medium Continuous Params \u274c No \u2705 Yes \u2705 Yes Best For Small discrete Large continuous Expensive evals"},{"location":"user_guide/hyperparameter_search/#decision-flow","title":"Decision Flow","text":"<p>Is search space &lt; 100 configs AND all discrete? \u251c\u2500 YES \u2192 Use Grid Search \u2514\u2500 NO  \u2192 Continue Is training cheap (&lt; 5 min/trial)? \u251c\u2500 YES \u2192 Use Random Search (20-50 trials) \u2514\u2500 NO  \u2192 Continue Can you run trials sequentially? \u251c\u2500 YES \u2192 Use Bayesian Optimization \u2514\u2500 NO  \u2192 Use Random Search with parallel execution</p>"},{"location":"user_guide/hyperparameter_search/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"user_guide/hyperparameter_search/#reduce-search-time","title":"Reduce Search Time","text":"<pre><code># 1. Use fewer epochs during search\nconfig.training.epochs = 5  # Instead of 100\n\n# 2. Use smaller dataset\ntrain_subset = Subset(train_dataset, range(5000))\n\n# 3. Parallelize (Grid/Random only)\nsearch.run(train_fn, n_jobs=4)\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#handle-different-parameter-types","title":"Handle Different Parameter Types","text":"<pre><code>from frameworm.search.space import Real, Integer, Categorical\n\nsearch_space = {\n    # Continuous (use log scale for learning rates)\n    'training.lr': Real(1e-5, 1e-2, log=True),\n\n    # Discrete integers (use log for batch sizes)\n    'training.batch_size': Integer(32, 256, log=True),\n\n    # Discrete choices\n    'optimizer': Categorical(['adam', 'sgd', 'rmsprop']),\n\n    # Linear continuous\n    'model.dropout': Real(0.0, 0.5, log=False)\n}\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#two-stage-search","title":"Two-Stage Search","text":"<pre><code># Stage 1: Coarse search with Random\ncoarse_search = RandomSearch(\n    config,\n    search_space_wide,\n    n_trials=50\n)\ncoarse_best = coarse_search.run(train_fn)\n\n# Stage 2: Fine-tune with Bayesian around best region\nfine_search_space = refine_space_around(coarse_best)\nfine_search = BayesianSearch(\n    config,\n    fine_search_space,\n    n_trials=20\n)\nfine_best = fine_search.run(train_fn)\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#common-issues","title":"Common Issues","text":""},{"location":"user_guide/hyperparameter_search/#out-of-memory-during-search","title":"Out of Memory During Search","text":"<pre><code># Solution: Reduce batch size during search\nconfig.training.batch_size = 64  # Instead of 128\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#search-takes-too-long","title":"Search Takes Too Long","text":"<pre><code># Solution 1: Reduce epochs\nconfig.training.epochs = 3\n\n# Solution 2: Parallel execution\nsearch.run(train_fn, n_jobs=4)\n\n# Solution 3: Reduce trials\nsearch.n_trials = 20  # Instead of 50\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#bayesian-optimization-not-converging","title":"Bayesian Optimization Not Converging","text":"<pre><code># Solution: Increase initial random points\nsearch = BayesianSearch(\n    ...\n    n_initial_points=15,  # More exploration\n    acquisition='ei'  # Balanced\n)\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#examples","title":"Examples","text":"<p>See: - <code>examples/hyperparameter_search_example.py</code> - Grid and Random - <code>examples/search_comparison_example.py</code> - All methods compared</p>"},{"location":"user_guide/hyperparameter_search/#training-function","title":"Training Function","text":"<p>Define a function that takes Config and returns metrics: <pre><code>def train_fn(config: Config) -&gt; dict:\n    # Get data\n    train_loader, val_loader = get_data(config.training.batch_size)\n\n    # Create model\n    model = get_model(\"vae\")(config)\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.training.lr)\n\n    # Train\n    trainer = Trainer(model, optimizer)\n    trainer.train(train_loader, val_loader, epochs=config.training.epochs)\n\n    # Return metrics\n    return {\n        'val_loss': trainer.state.val_metrics['loss'][-1],\n        'train_loss': trainer.state.train_metrics['loss'][-1]\n    }\n</code></pre></p>"},{"location":"user_guide/hyperparameter_search/#parallel-execution","title":"Parallel Execution","text":"<p>Run multiple trials in parallel: <pre><code>best_config, best_score = search.run(\n    train_fn=train_fn,\n    n_jobs=4  # Use 4 processes\n)\n\n# Use all CPUs\nsearch.run(train_fn, n_jobs=-1)\n</code></pre></p>"},{"location":"user_guide/hyperparameter_search/#experiment-tracking","title":"Experiment Tracking","text":"<p>Automatically track all trials: <pre><code>search.run(\n    train_fn=train_fn,\n    experiment_root='experiments/search'\n)\n\n# Each trial becomes an experiment\n# Compare with ExperimentManager\nfrom frameworm.experiment import ExperimentManager\nmanager = ExperimentManager('experiments/search')\ndf = manager.list_experiments(tags=['grid_search'])\n</code></pre></p>"},{"location":"user_guide/hyperparameter_search/#analysis","title":"Analysis","text":""},{"location":"user_guide/hyperparameter_search/#analyze-results","title":"Analyze Results","text":"<pre><code>from frameworm.search import SearchAnalyzer\n\nanalyzer = SearchAnalyzer(search.results)\n\n# Print summary\nanalyzer.print_summary()\n\n# Plot convergence\nanalyzer.plot_convergence(save_path='convergence.png')\n\n# Plot parameter importance\nanalyzer.plot_parameter_importance(save_path='importance.png')\n\n# Plot parameter vs score\nanalyzer.plot_parameter_vs_score('training.lr', save_path='lr_vs_score.png')\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#get-best-configurations","title":"Get Best Configurations","text":"<pre><code># Top 5 configs\ntop5 = analyzer.get_best_n(5)\nprint(top5)\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#saveload-results","title":"Save/Load Results","text":"<pre><code># Save\nsearch.save_results('search_results.json')\n\n# Load\nsearch2 = GridSearch(base_config, search_space)\nsearch2.load_results('search_results.json')\n</code></pre>"},{"location":"user_guide/hyperparameter_search/#best-practices","title":"Best Practices","text":"<ol> <li>Start with random search - More efficient for most cases</li> <li>Use log scale - For learning rates, batch sizes</li> <li>Run enough trials - At least 20-50 for random search</li> <li>Reduce training time - Use fewer epochs during search</li> <li>Track experiments - Easy to compare later</li> <li>Analyze results - Understand parameter importance</li> <li>Validate best config - Train with full epochs</li> </ol>"},{"location":"user_guide/hyperparameter_search/#examples_1","title":"Examples","text":"<p>See <code>examples/hyperparameter_search_example.py</code> for complete example.</p>"},{"location":"user_guide/metrics/","title":"Advanced Metrics","text":""},{"location":"user_guide/metrics/#overview","title":"Overview","text":"<p>Frameworm provides production-grade metrics for evaluating generative models.</p>"},{"location":"user_guide/metrics/#available-metrics","title":"Available Metrics","text":""},{"location":"user_guide/metrics/#fid-frechet-inception-distance","title":"FID (Fr\u00e9chet Inception Distance)","text":"<p>Measures quality and diversity of generated images.</p> <p>Lower is better (0 = identical distributions) <pre><code>from frameworm.metrics import FID\n\nfid = FID(device='cuda')\nscore = fid.compute(real_images, generated_images)\nprint(f\"FID: {score:.2f}\")\n</code></pre></p>"},{"location":"user_guide/metrics/#inception-score-is","title":"Inception Score (IS)","text":"<p>Measures quality and diversity based on classifier confidence.</p> <p>Higher is better (typical range: 1-10+) <pre><code>from frameworm.metrics import InceptionScore\n\ninception_score = InceptionScore(device='cuda')\nscore, std = inception_score.compute(generated_images)\nprint(f\"IS: {score:.2f} \u00b1 {std:.2f}\")\n</code></pre></p>"},{"location":"user_guide/metrics/#lpips-learned-perceptual-similarity","title":"LPIPS (Learned Perceptual Similarity)","text":"<p>Measures perceptual similarity between images.</p> <p>Lower is better (0 = identical, 1 = very different) <pre><code>from frameworm.metrics import LPIPS\n\nlpips = LPIPS(device='cuda')\ndistance = lpips.compute(image1, image2)\nprint(f\"LPIPS: {distance:.4f}\")\n</code></pre></p>"},{"location":"user_guide/metrics/#unified-evaluation","title":"Unified Evaluation","text":""},{"location":"user_guide/metrics/#metricevaluator","title":"MetricEvaluator","text":"<p>Evaluate with multiple metrics at once: <pre><code>from frameworm.metrics import MetricEvaluator\n\nevaluator = MetricEvaluator(\n    metrics=['fid', 'is', 'lpips'],\n    real_data=real_loader,\n    device='cuda'\n)\n\nresults = evaluator.evaluate(model, num_samples=10000)\n# {'fid': 25.3, 'is': 8.5, 'is_std': 0.3, 'lpips': 0.45}\n</code></pre></p>"},{"location":"user_guide/metrics/#quick-evaluation","title":"Quick Evaluation","text":"<pre><code>from frameworm.metrics import quick_evaluate\n\nresults = quick_evaluate(\n    model,\n    real_data=real_images,\n    num_samples=5000,\n    device='cuda'\n)\n</code></pre>"},{"location":"user_guide/metrics/#integration-with-training","title":"Integration with Training","text":""},{"location":"user_guide/metrics/#automatic-evaluation","title":"Automatic Evaluation","text":"<pre><code>from frameworm.training import Trainer\nfrom frameworm.metrics import MetricEvaluator\n\nevaluator = MetricEvaluator(\n    metrics=['fid', 'is'],\n    real_data=real_loader,\n    device='cuda'\n)\n\ntrainer = Trainer(model, optimizer)\ntrainer.set_evaluator(evaluator, eval_every=5)\n\n# Automatically evaluates every 5 epochs\ntrainer.train(train_loader, val_loader, epochs=100)\n</code></pre>"},{"location":"user_guide/metrics/#manual-evaluation","title":"Manual Evaluation","text":"<pre><code># Evaluate at specific points\nresults = evaluator.evaluate(model, num_samples=10000)\n\n# Log to experiment\nif trainer.experiment:\n    for metric_name, value in results.items():\n        trainer.experiment.log_metric(\n            f\"eval_{metric_name}\",\n            value,\n            epoch=epoch\n        )\n</code></pre>"},{"location":"user_guide/metrics/#best-practices","title":"Best Practices","text":"<ol> <li>Use enough samples - At least 5000-10000 for FID/IS</li> <li>Match data distribution - Evaluate on same distribution as training</li> <li>Track over time - Monitor metrics during training</li> <li>Compare fairly - Same number of samples for all models</li> <li>Use multiple metrics - No single metric tells the whole story</li> </ol>"},{"location":"user_guide/metrics/#interpreting-metrics","title":"Interpreting Metrics","text":""},{"location":"user_guide/metrics/#fid","title":"FID","text":"<ul> <li>&lt; 10: Excellent quality</li> <li>10-30: Good quality</li> <li>30-50: Moderate quality</li> <li>&gt; 50: Poor quality</li> </ul>"},{"location":"user_guide/metrics/#is","title":"IS","text":"<ul> <li>&gt; 10: Excellent diversity and quality</li> <li>5-10: Good</li> <li>&lt; 5: Poor</li> </ul>"},{"location":"user_guide/metrics/#lpips","title":"LPIPS","text":"<ul> <li>&lt; 0.1: Very similar</li> <li>0.1-0.3: Moderately similar</li> <li>&gt; 0.3: Quite different</li> </ul>"},{"location":"user_guide/metrics/#common-issues","title":"Common Issues","text":""},{"location":"user_guide/metrics/#out-of-memory","title":"Out of Memory","text":"<pre><code># Reduce batch size\nevaluator = MetricEvaluator(\n    metrics=['fid'],\n    real_data=real_loader,\n    device='cuda',\n    batch_size=50  # Reduce from default 100\n)\n</code></pre>"},{"location":"user_guide/metrics/#slow-evaluation","title":"Slow Evaluation","text":"<pre><code># Use fewer samples for development\nresults = evaluator.evaluate(model, num_samples=1000)\n\n# Use full samples for final evaluation\nresults = evaluator.evaluate(model, num_samples=50000)\n</code></pre>"},{"location":"user_guide/metrics/#examples","title":"Examples","text":"<p>See <code>examples/advanced_metrics_example.py</code> for complete example.</p>"},{"location":"user_guide/models/","title":"Models","text":""},{"location":"user_guide/models/#available-models","title":"Available Models","text":""},{"location":"user_guide/models/#dcgan","title":"DCGAN","text":"<p>Deep Convolutional GAN for image generation.</p> <p>Usage: <pre><code>from frameworm.core import Config, get_model\n\n# Load config\ncfg = Config('configs/models/gan/dcgan.yaml')\n\n# Get model\nmodel_class = get_model(\"dcgan\")\nmodel = model_class(cfg)\n\n# Generate images\nimport torch\nz = torch.randn(4, 100, 1, 1)\nimages = model(z)  # (4, 3, 64, 64)\n</code></pre></p> <p>Config Options: <pre><code>model:\n  type: dcgan\n  latent_dim: 100      # Latent vector dimension\n  image_size: 64       # Output image size\n  channels: 3          # Color channels\n  ngf: 64             # Generator feature maps\n  ndf: 64             # Discriminator feature maps\n</code></pre></p> <p>Architecture: - Generator: 4 transposed conv layers - Discriminator: 4 conv layers - BatchNorm + ReLU/LeakyReLU</p>"},{"location":"user_guide/models/#creating-custom-models","title":"Creating Custom Models","text":"<p>See Plugin Guide for creating custom models.</p>"},{"location":"user_guide/models/#requirements","title":"Requirements","text":"<ul> <li>Inherit from <code>BaseModel</code></li> <li>Implement <code>forward()</code> method</li> <li>Register with <code>@register_model()</code></li> </ul>"},{"location":"user_guide/models/#example","title":"Example","text":"<pre><code>from frameworm.models import BaseModel\nfrom frameworm.core import register_model\nimport torch.nn as nn\n\n@register_model(\"my-model\")\nclass MyModel(BaseModel):\n    def __init__(self, config):\n        super().__init__(config)\n\n        # Build architecture\n        self.net = nn.Sequential(\n            nn.Linear(config.model.input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, config.model.output_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n</code></pre>"},{"location":"user_guide/models/#vae-variational-autoencoder","title":"VAE (Variational Autoencoder)","text":"<p>Learn a latent representation and generate new samples.</p> <p>Usage: <pre><code>from frameworm.core import Config, get_model\nimport torch\n\n# Load config\ncfg = Config('configs/models/vae/vanilla.yaml')\n\n# Get model\nvae = get_model(\"vae\")(cfg)\n\n# Reconstruct images\nimages = torch.rand(4, 3, 64, 64)\nreconstructed = vae.reconstruct(images)\n\n# Generate new samples\nsamples = vae.sample(16)\n\n# Training\nrecon, mu, logvar = vae(images)\nloss_dict = vae.compute_loss(images, recon, mu, logvar)\nloss = loss_dict['loss']\n</code></pre></p> <p>Config Options: <pre><code>model:\n  type: vae\n  latent_dim: 128      # Latent space dimension\n  image_size: 64       # Input image size\n  channels: 3          # Color channels\n  beta: 1.0           # \u03b2 coefficient (&gt;1 for \u03b2-VAE)\n</code></pre></p> <p>\u03b2-VAE:</p> <p>Use \u03b2 &gt; 1 for better disentanglement: <pre><code>model:\n  beta: 4.0  # Emphasizes KL divergence\n</code></pre></p> <p>Architecture: - Encoder: 4 conv layers \u2192 latent distribution - Reparameterization: z = \u03bc + \u03c3 * \u03b5 - Decoder: 4 transposed conv layers \u2192 reconstruction</p> <p>Loss: - Reconstruction: MSE between input and output - KL Divergence: Regularization to N(0, I) - Total: recon_loss + \u03b2 * kl_loss</p>"},{"location":"user_guide/models/#ddpm-denoising-diffusion-probabilistic-model","title":"DDPM (Denoising Diffusion Probabilistic Model)","text":"<p>Generate images through iterative denoising.</p> <p>Usage: <pre><code>from frameworm.core import Config, get_model\nimport torch\n\n# Load config\ncfg = Config('configs/models/diffusion/ddpm.yaml')\n\n# Get model\nddpm = get_model(\"ddpm\")(cfg)\n\n# Generate samples (slow - 1000 steps)\nsamples = ddpm.sample(batch_size=8)\n\n# Training\nx = torch.rand(batch, 3, 64, 64)\nloss_dict = ddpm.compute_loss(x)\nloss = loss_dict['loss']\n</code></pre></p> <p>Config Options: <pre><code>model:\n  type: ddpm\n  timesteps: 1000      # Number of diffusion steps\n  image_size: 64       # Output image size\n  channels: 3          # Color channels\n  base_channels: 128   # U-Net base channels\n</code></pre></p> <p>Architecture: - U-Net with time embeddings - 1000 denoising steps - Linear beta schedule - MSE loss on noise prediction</p> <p>Notes: - Generation is slow (~1000 forward passes) - Requires substantial training - Quality improves with more timesteps - Use EMA for best results</p> <p>Advantages: - High-quality samples - Stable training - Principled framework</p> <p>Disadvantages: - Very slow sampling - Computationally expensive</p>"},{"location":"user_guide/plugins/","title":"Plugin System","text":""},{"location":"user_guide/plugins/#overview","title":"Overview","text":"<p>Frameworm's plugin system allows you to extend the framework with custom components without modifying the core code.</p>"},{"location":"user_guide/plugins/#quick-start","title":"Quick Start","text":""},{"location":"user_guide/plugins/#1-create-a-plugin","title":"1. Create a Plugin","text":"<p>Create a Python file in the <code>plugins/</code> directory: <pre><code># plugins/my_model.py\nfrom frameworm.models import BaseModel\nfrom frameworm.core import register_model\n\n@register_model(\"my-model\")\nclass MyModel(BaseModel):\n    def __init__(self, config):\n        super().__init__(config)\n        # Your architecture here\n\n    def forward(self, x):\n        # Your forward pass here\n        return x\n</code></pre></p>"},{"location":"user_guide/plugins/#2-use-your-plugin","title":"2. Use Your Plugin","text":"<pre><code>from frameworm.core import get_model, Config\n\n# Auto-discovered!\nmodel_class = get_model(\"my-model\")\nmodel = model_class(config)\n</code></pre> <p>That's it! No imports, no registration code in your main script.</p>"},{"location":"user_guide/plugins/#plugin-types","title":"Plugin Types","text":""},{"location":"user_guide/plugins/#models","title":"Models","text":"<pre><code>@register_model(\"name\", version=\"1.0\", author=\"you\")\nclass MyModel(BaseModel):\n    def forward(self, x):\n        ...\n</code></pre> <p>Requirements: - Inherit from <code>BaseModel</code> - Implement <code>forward()</code> method</p>"},{"location":"user_guide/plugins/#trainers","title":"Trainers","text":"<pre><code>@register_trainer(\"name\")\nclass MyTrainer(BaseTrainer):\n    def training_step(self, batch, batch_idx):\n        ...\n\n    def validation_step(self, batch, batch_idx):\n        ...\n</code></pre> <p>Requirements: - Inherit from <code>BaseTrainer</code> - Implement <code>training_step()</code> and <code>validation_step()</code></p>"},{"location":"user_guide/plugins/#pipelines","title":"Pipelines","text":"<pre><code>@register_pipeline(\"name\")\nclass MyPipeline(BasePipeline):\n    def run(self, *args, **kwargs):\n        ...\n</code></pre> <p>Requirements: - Inherit from <code>BasePipeline</code> - Implement <code>run()</code> method</p>"},{"location":"user_guide/plugins/#datasets","title":"Datasets","text":"<pre><code>@register_dataset(\"name\")\nclass MyDataset:\n    def __len__(self):\n        ...\n\n    def __getitem__(self, idx):\n        ...\n</code></pre> <p>Requirements: - Implement <code>__len__()</code> and <code>__getitem__()</code></p>"},{"location":"user_guide/plugins/#auto-discovery","title":"Auto-Discovery","text":"<p>Plugins are automatically discovered when: - First access (get/list) - Manual discovery</p>"},{"location":"user_guide/plugins/#disable-auto-discovery","title":"Disable Auto-Discovery","text":"<pre><code>from frameworm.core import set_auto_discover\n\nset_auto_discover(False)\n\n# Now you must manually discover\nfrom frameworm.core import discover_plugins\ndiscover_plugins()\n</code></pre>"},{"location":"user_guide/plugins/#advanced-features","title":"Advanced Features","text":""},{"location":"user_guide/plugins/#search","title":"Search","text":"<pre><code>from frameworm.core import search_models\n\n# Find all GAN models\ngan_models = search_models(\"gan\")\n</code></pre>"},{"location":"user_guide/plugins/#metadata","title":"Metadata","text":"<pre><code>from frameworm.core import get_model_metadata\n\nmetadata = get_model_metadata(\"my-model\")\nprint(f\"Version: {metadata['version']}\")\nprint(f\"Author: {metadata['author']}\")\n</code></pre>"},{"location":"user_guide/plugins/#registry-summary","title":"Registry Summary","text":"<pre><code>from frameworm.core import print_registry_summary\n\nprint_registry_summary()\n</code></pre>"},{"location":"user_guide/plugins/#best-practices","title":"Best Practices","text":"<ol> <li>One plugin per file</li> <li>Descriptive names</li> <li>Add metadata (version, author, description)</li> <li>Include docstrings</li> <li>Test your plugins</li> <li>Keep dependencies minimal</li> </ol>"},{"location":"user_guide/plugins/#organization","title":"Organization","text":"<p>Organize plugins in subdirectories: plugins/ \u251c\u2500\u2500 models/ \u2502   \u251c\u2500\u2500 gans/ \u2502   \u2502   \u251c\u2500\u2500 stylegan.py \u2502   \u2502   \u2514\u2500\u2500 dcgan.py \u2502   \u2514\u2500\u2500 diffusion/ \u2502       \u2514\u2500\u2500 ddpm.py \u251c\u2500\u2500 trainers/ \u2502   \u2514\u2500\u2500 custom_trainer.py \u2514\u2500\u2500 utils/ \u2514\u2500\u2500 helpers.py</p> <p>All <code>.py</code> files are discovered recursively.</p>"},{"location":"user_guide/plugins/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/plugins/#testing-plugins","title":"Testing Plugins","text":""},{"location":"user_guide/plugins/#unit-testing","title":"Unit Testing","text":"<pre><code># tests/plugins/test_my_plugin.py\nfrom frameworm.core import register_model, get_model\nfrom frameworm.models import BaseModel\n\ndef test_my_plugin():\n    @register_model(\"test-plugin\")\n    class TestPlugin(BaseModel):\n        def __init__(self, config):\n            super().__init__(config)\n        def forward(self, x):\n            return x\n\n    model_class = get_model(\"test-plugin\")\n    assert model_class is not None\n</code></pre>"},{"location":"user_guide/plugins/#integration-testing","title":"Integration Testing","text":"<pre><code>def test_plugin_with_config():\n    model_class = get_model(\"my-plugin\")\n    model = model_class(config)\n\n    # Test functionality\n    output = model(input_data)\n    assert output.shape == expected_shape\n</code></pre>"},{"location":"user_guide/plugins/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"user_guide/plugins/#common-issues","title":"Common Issues","text":"<p>Plugin not discovered: <pre><code>from frameworm.core import reset_discovery, discover_plugins\nreset_discovery()\ndiscover_plugins(force=True)\n</code></pre></p> <p>Import errors: - Check plugin file has no syntax errors - Ensure all dependencies are installed - Verify plugin inherits from correct base class</p> <p>Validation errors: - Ensure required methods are implemented - Check method signatures match base class</p>"},{"location":"user_guide/plugins/#plugin-not-found","title":"Plugin Not Found","text":"<pre><code># Check if plugin was discovered\nfrom frameworm.core import list_models, discover_plugins\n\nprint(list_models())  # See all models\n\n# Force re-discovery\nfrom frameworm.core import reset_discovery\nreset_discovery()\ndiscover_plugins(force=True)\n</code></pre>"},{"location":"user_guide/plugins/#import-errors","title":"Import Errors","text":"<p>Plugin files with import errors are skipped with a warning: Warning: Failed to import plugin plugins/my_model.py: ModuleNotFoundError Check your plugin file for errors.</p>"},{"location":"user_guide/plugins/#validation-errors","title":"Validation Errors","text":"<p>If your plugin doesn't meet requirements: <pre><code>TypeError: Model class MyModel must implement forward() method\n</code></pre></p> <p>Ensure your plugin implements all required methods.</p>"},{"location":"user_guide/plugins/#examples","title":"Examples","text":"<p>See <code>examples/custom_plugin.py</code> for complete working examples.</p> <p>See <code>plugins/README.md</code> for quick reference.</p>"},{"location":"user_guide/training/","title":"Training Guide","text":""},{"location":"user_guide/training/#basic-training","title":"Basic Training","text":""},{"location":"user_guide/training/#simple-training-loop","title":"Simple Training Loop","text":"<pre><code>from frameworm.training import Trainer\nfrom frameworm.core import Config, get_model\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n# Create model\nmodel = get_model(\"vae\")(config)\n\n# Create optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Create trainer\ntrainer = Trainer(\n    model=model,\n    optimizer=optimizer,\n    device='cuda'\n)\n\n# Train\ntrainer.train(train_loader, val_loader, epochs=100)\n</code></pre>"},{"location":"user_guide/training/#learning-rate-scheduling","title":"Learning Rate Scheduling","text":""},{"location":"user_guide/training/#built-in-schedulers","title":"Built-in Schedulers","text":"<pre><code>from torch.optim.lr_scheduler import CosineAnnealingLR\n\nscheduler = CosineAnnealingLR(optimizer, T_max=100)\ntrainer.set_scheduler(scheduler)\n</code></pre>"},{"location":"user_guide/training/#custom-schedulers","title":"Custom Schedulers","text":"<pre><code>from frameworm.training.schedulers import WarmupCosineScheduler\n\nscheduler = WarmupCosineScheduler(\n    optimizer,\n    warmup_epochs=10,\n    total_epochs=100,\n    min_lr=1e-6\n)\ntrainer.set_scheduler(scheduler)\n</code></pre>"},{"location":"user_guide/training/#callbacks","title":"Callbacks","text":""},{"location":"user_guide/training/#csv-logging","title":"CSV Logging","text":"<pre><code>from frameworm.training.callbacks import CSVLogger\n\ntrainer.add_callback(CSVLogger('training.csv'))\n</code></pre>"},{"location":"user_guide/training/#model-checkpointing","title":"Model Checkpointing","text":"<pre><code>from frameworm.training.callbacks import ModelCheckpoint\n\ntrainer.add_callback(ModelCheckpoint(\n    'model_{epoch}.pt',\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True\n))\n</code></pre>"},{"location":"user_guide/training/#custom-callbacks","title":"Custom Callbacks","text":"<pre><code>from frameworm.training.callbacks import Callback\n\nclass MyCallback(Callback):\n    def on_epoch_end(self, epoch, metrics, trainer):\n        print(f\"Custom action at epoch {epoch}\")\n\ntrainer.add_callback(MyCallback())\n</code></pre>"},{"location":"user_guide/training/#early-stopping","title":"Early Stopping","text":"<pre><code>trainer.set_early_stopping(patience=10, min_delta=0.001)\n</code></pre>"},{"location":"user_guide/training/#resuming-training","title":"Resuming Training","text":"<pre><code># Train\ntrainer.train(train_loader, val_loader, epochs=100)\n\n# Resume from checkpoint\ntrainer.train(\n    train_loader,\n    val_loader,\n    epochs=200,\n    resume_from='checkpoints/latest.pt'\n)\n</code></pre>"},{"location":"user_guide/training/#advanced-features","title":"Advanced Features","text":""},{"location":"user_guide/training/#gan-training","title":"GAN Training","text":"<p>See <code>examples/train_dcgan.py</code> for complete GAN training example.</p>"},{"location":"user_guide/training/#multiple-optimizers","title":"Multiple Optimizers","text":"<p>For models requiring multiple optimizers (like GANs), subclass Trainer and override <code>train_epoch()</code>.</p>"},{"location":"user_guide/training/#custom-loss-functions","title":"Custom Loss Functions","text":"<pre><code>def custom_loss(outputs, targets):\n    return ((outputs - targets) ** 2).mean()\n\ntrainer = Trainer(model, optimizer, criterion=custom_loss)\n</code></pre>"},{"location":"user_guide/training/#best-practices","title":"Best Practices","text":"<ol> <li>Start with small learning rate - Use 1e-4 or 1e-3</li> <li>Use warmup - Especially for large models</li> <li>Monitor validation - Watch for overfitting</li> <li>Save checkpoints - Enable resume</li> <li>Use callbacks - Log everything</li> <li>Early stopping - Save time</li> <li>LR scheduling - Improve convergence</li> </ol>"},{"location":"user_guide/training/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/training/#loss-is-nan","title":"Loss is NaN","text":"<ul> <li>Reduce learning rate</li> <li>Add gradient clipping (Day 8)</li> <li>Check data normalization</li> <li>Use mixed precision (Day 8)</li> </ul>"},{"location":"user_guide/training/#not-converging","title":"Not Converging","text":"<ul> <li>Increase learning rate</li> <li>Try different scheduler</li> <li>Check model architecture</li> <li>Verify data quality</li> </ul>"},{"location":"user_guide/training/#out-of-memory","title":"Out of Memory","text":"<ul> <li>Reduce batch size</li> <li>Use gradient accumulation (Day 8)</li> <li>Enable mixed precision (Day 8)</li> </ul>"},{"location":"user_guide/vae_design/","title":"Variational Autoencoder (VAE) Design","text":""},{"location":"user_guide/vae_design/#architecture","title":"Architecture","text":""},{"location":"user_guide/vae_design/#encoder","title":"Encoder","text":"<ul> <li>Input: (B, C, H, W) image</li> <li>Conv layers to compress</li> <li>Output: mean (\u03bc) and log_variance (log \u03c3\u00b2)</li> </ul>"},{"location":"user_guide/vae_design/#reparameterization","title":"Reparameterization","text":"<ul> <li>Sample \u03b5 ~ N(0, 1)</li> <li>z = \u03bc + \u03c3 * \u03b5</li> </ul>"},{"location":"user_guide/vae_design/#decoder","title":"Decoder","text":"<ul> <li>Input: z (latent vector)</li> <li>Transposed conv to reconstruct</li> <li>Output: (B, C, H, W) reconstructed image</li> </ul>"},{"location":"user_guide/vae_design/#loss-function","title":"Loss Function","text":"<ul> <li>Reconstruction loss (MSE or BCE)</li> <li>KL divergence: -0.5 * sum(1 + log(\u03c3\u00b2) - \u03bc\u00b2 - \u03c3\u00b2)</li> </ul>"},{"location":"user_guide/vae_design/#config","title":"Config","text":"<pre><code>model:\n  type: vae\n  latent_dim: 128\n  image_size: 64\n  channels: 3\n  beta: 1.0  # \u03b2-VAE coefficient\n</code></pre>"}]}